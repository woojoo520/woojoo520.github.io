<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="a study blog">
<meta property="og:type" content="website">
<meta property="og:title" content="Celery Fairy">
<meta property="og:url" content="https://woojoo520.github.io/page/7/index.html">
<meta property="og:site_name" content="Celery Fairy">
<meta property="og:description" content="a study blog">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Celery Fairy">
<meta name="twitter:description" content="a study blog">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://woojoo520.github.io/page/7/">





  <title>Celery Fairy</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <a href="https://github.com/woojoo520" class="github-corner" aria-label="View source on GitHub">
      <svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/>
      </svg>
    </a>
    <style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Celery Fairy</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Celery's Blog</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://woojoo520.github.io/2019/08/21/LeetCode-Day7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mariana">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Celery Fairy">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/21/LeetCode-Day7/" itemprop="url">LeetCode-Day7</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-21T21:21:16+08:00">
                2019-08-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="22-括号生成"><a href="#22-括号生成" class="headerlink" title="22. 括号生成"></a>22. 括号生成</h3><p>给出 n 代表生成括号的对数，请你写出一个函数，使其能够生成所有可能的并且有效的括号组合。</p>
<p>例如，给出 n = 3，生成结果为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">  &quot;((()))&quot;,</span><br><span class="line">  &quot;(()())&quot;,</span><br><span class="line">  &quot;(())()&quot;,</span><br><span class="line">  &quot;()(())&quot;,</span><br><span class="line">  &quot;()()()&quot;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> N, <span class="keyword">int</span> l, <span class="keyword">int</span> r,<span class="built_in">string</span> str, <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp; ans)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(r &gt; l || l &gt; N || r &gt; N) &#123;</span><br><span class="line">            <span class="keyword">return</span> ;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(l == r &amp;&amp; l == N) &#123;</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; str &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">            ans.push_back(str);</span><br><span class="line">            <span class="keyword">return</span> ;</span><br><span class="line">        &#125;</span><br><span class="line">        dfs(N, l + <span class="number">1</span>, r, str + <span class="string">'('</span>, ans);</span><br><span class="line">        dfs(N, l, r + <span class="number">1</span>, str + <span class="string">')'</span>, ans);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; generateParenthesis(<span class="keyword">int</span> n) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; ans;</span><br><span class="line">        dfs(n, <span class="number">0</span>, <span class="number">0</span>, <span class="string">""</span>, ans);</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125; </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>解释：暴力构造法+剪枝（递归）</p>
<p>递归出口:</p>
<ul>
<li><p>左括号数量小于右括号数量</p>
</li>
<li><p>左括号或右括号的数量大于n</p>
</li>
<li><p>左括号数量和有括号数量相等，且等于n，即符合题意的解</p>
</li>
</ul>
<h3 id="23-合并k个排序链表"><a href="#23-合并k个排序链表" class="headerlink" title="23. 合并k个排序链表"></a>23. 合并k个排序链表</h3><p>合并 k 个排序链表，返回合并后的排序链表。请分析和描述算法的复杂度。</p>
<p>示例:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">输入:</span><br><span class="line">[</span><br><span class="line">  1-&gt;4-&gt;5,</span><br><span class="line">  1-&gt;3-&gt;4,</span><br><span class="line">  2-&gt;6</span><br><span class="line">]</span><br><span class="line">输出: 1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4-&gt;5-&gt;6</span><br></pre></td></tr></table></figure>

<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * struct ListNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode *next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) : val(x), next(NULL) &#123;&#125;</span></span><br><span class="line"><span class="comment"> * &#125;;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">     <span class="function">ListNode* <span class="title">mergeTwoLists</span><span class="params">(ListNode* l1, ListNode* l2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(l1 == <span class="literal">NULL</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> l2;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(l2 == <span class="literal">NULL</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> l1;</span><br><span class="line">        &#125;</span><br><span class="line">        ListNode* cur = (ListNode*)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(ListNode));</span><br><span class="line">        ListNode* htmp = cur;</span><br><span class="line">        ListNode* cur1 = l1;</span><br><span class="line">        ListNode* cur2 = l2;</span><br><span class="line">        <span class="keyword">while</span>(cur1 != <span class="literal">NULL</span> &amp;&amp; cur2 != <span class="literal">NULL</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span>(cur1-&gt;val &lt;= cur2-&gt;val) &#123;</span><br><span class="line">                cur-&gt;next = cur1;</span><br><span class="line">                cur1 = cur1-&gt;next;</span><br><span class="line">                cur = cur-&gt;next;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                cur-&gt;next = cur2;</span><br><span class="line">                cur2 = cur2-&gt;next;</span><br><span class="line">                cur = cur-&gt;next;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(cur1 != <span class="literal">NULL</span>) &#123;</span><br><span class="line">            cur-&gt;next = cur1;</span><br><span class="line">        &#125; </span><br><span class="line">        <span class="keyword">if</span>(cur2 != <span class="literal">NULL</span>) &#123;</span><br><span class="line">            cur-&gt;next = cur2;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> htmp-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ListNode* _mergeKLists(<span class="built_in">vector</span>&lt;ListNode*&gt;&amp; lists, <span class="keyword">int</span> begin, <span class="keyword">int</span> end) &#123;</span><br><span class="line">        <span class="keyword">if</span>(end &lt; begin) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(end == begin) &#123;</span><br><span class="line">            <span class="keyword">return</span> lists[begin];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> mid = (begin + end) / <span class="number">2</span>;</span><br><span class="line">        ListNode* p1 = _mergeKLists(lists, begin, mid);</span><br><span class="line">        ListNode* p2 = _mergeKLists(lists, mid + <span class="number">1</span>, end);</span><br><span class="line">        <span class="keyword">return</span> mergeTwoLists(p1, p2);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">ListNode* <span class="title">mergeKLists</span><span class="params">(<span class="built_in">vector</span>&lt;ListNode*&gt;&amp; lists)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> _mergeKLists(lists, <span class="number">0</span>, lists.size() - <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>解释：关于k路归并，这里采用了优先队列合并</p>
<p>递归 + 二分</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://woojoo520.github.io/2019/08/21/ZSL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mariana">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Celery Fairy">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/21/ZSL/" itemprop="url">ZSL</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-21T16:42:41+08:00">
                2019-08-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="ZSL的相关论文"><a href="#ZSL的相关论文" class="headerlink" title="ZSL的相关论文"></a>ZSL的相关论文</h2><ol>
<li>基于attribute description构建语义空间A</li>
</ol>
<p>$Learning To Detect Unseen Object Classes by Between-Class Attribute Transfer$</p>
<p><a href="http://pub.ist.ac.at/~chl/papers/lampert-cvpr2009.pdf" target="_blank" rel="noopener">http://pub.ist.ac.at/~chl/papers/lampert-cvpr2009.pdf</a></p>
<p>基于attribute description的方法，其数据集中的每张图片都标注了若干attribute用以描述图片信息。一些标注了attribute的示例图片如下图所示</p>
<p><img src="http://blog.openkg.cn/wp-content/uploads/2018/11/word-image-3.jpeg" alt="img"></p>
<p>这篇论文通过上述每张图片预定义的特征，构建了样本数据的特征表示空间X；同时，通过若干classes集合或图片集合学习可用于表示数据集中所有class的attribute description，完成语义空间A的构建；最后，论文提出了使用两种方式建立X和A之间的映射。两种方式为：Direct Attribute Prediction（DAP）和 Indirect Attribute Prediction（IAP），如下图所示：</p>
<p><img src="http://blog.openkg.cn/wp-content/uploads/2018/11/word-image-4.jpeg" alt="img"></p>
<p><strong>DAP：</strong></p>
<p>训练时，由一直标签的训练集，学习有关attribute的参数β；预测时，为每一个测试样本预测其attribute参数，进而根据attribute建立的seen class(y) 和 unseen class(z)之间的关系，推导得出测试样本的label</p>
<p><strong>IAP：</strong></p>
<p>训练时，按多分类的方式学习参数α；预测时，根据attribute建立的seen class(y) 和 unseen class(z)之间的关系，推到得到unseen class 的分布。</p>
<p>DAP在训练是仅依据属性层，而IAP将训练样本的类标也作为一个中间层，一定程度上能限定测试样本生成新类标的范围，使得学习到的链接控制在对于Y来说，有意义的范围之内，因此可以增强系统的鲁棒性。但实际上，在作者后面的实验中，DAP的效果要比IAP好很多</p>
<p>效果虽然不是很好，但确实在一定程度上表达了“知识迁移”的思想，不仅利用图片训练相应的特征，更是加入了属性这类的高位特征描述，实现了“从低维图片特征分类器”到“高位语义特征（属性）分类器”的转变</p>
<p><strong>Attribute description相关论文列表：</strong></p>
<ul>
<li><cvpr-2009>Describing Objects by their Attributes</cvpr-2009></li>
<li><tpami-2014>Attribute-based Classification for Zero-Shot Visual Object Categorization</tpami-2014></li>
<li><tpami-2017>Zero-Shot Learning-A Comprehensive Evaluation of the Good, the Bad and the Ugly</tpami-2017></li>
<li><cvpr-2017>Semantic Autoencoder for Zero-Shot Learning</cvpr-2017></li>
<li><cvpr-2016>Recovering the Missing Link: Predicting Class-Attribute Associations for Unsupervised Zero-Shot Learning</cvpr-2016></li>
</ul>
<h3 id="2-基于embedding表示构建语义空间A"><a href="#2-基于embedding表示构建语义空间A" class="headerlink" title="2. 基于embedding表示构建语义空间A"></a>2. 基于embedding表示构建语义空间A</h3><p>$DeViSE: A Deep Visual-Semantic Embedding Model$</p>
<p><a href="http://papers.nips.cc/paper/5204-devise-a-deep-visual-semantic-embedding-model.pdf" target="_blank" rel="noopener">http://papers.nips.cc/paper/5204-devise-a-deep-visual-semantic-embedding-model.pdf</a></p>
<p>本文提出的DeViSE模型，数据集每个class/label可作为一个词在语义空间进行embedding表示，如使用与训练skip-gram模型得到有关class的language feature vector，同时利用与训练的CNN-based模型提取图片的visual feature vector，将两个向量映射到同一纬度的空间，进行相似度的计算。测试时，即可根据语义之间的相似性进行图片的分类。模型结构如下图：</p>
<p><img src="http://blog.openkg.cn/wp-content/uploads/2018/11/word-image-6.jpeg" alt="img"></p>
<p>考虑到训练时负样本发挥的通，模型的损失函数选择hinge loss。其中，通过dot-product 计算相似度。</p>
<p>$\text {loss(image,label)}=\sum_{j \neq l a b e l} \max \left[0, \text {margin }-\overrightarrow{t_{l a b e l}} M \vec{v}(\text {image})+\vec{t}_{j} M \vec{v}(\text {image})\right]$</p>
<p><strong>Embedding表示相关论文列表：</strong></p>
<ul>
<li><iccv-2015>Predicting Deep Zero-Shot Convolutional Neural Networks using TextualDescriptions</iccv-2015></li>
<li><cvpr-2016>Learning Deep Representations of Fine-grained Visual Descriptions</cvpr-2016></li>
<li><cvpr-2015>Evaluation of Output Embeddings for Fine-grained Image Classification</cvpr-2015></li>
<li><cvpr-2016>Latent Embeddings for Zero-shot Classification</cvpr-2016></li>
</ul>
<h3 id="3-基于KG-KB构建语义空间A"><a href="#3-基于KG-KB构建语义空间A" class="headerlink" title="3. 基于KG/KB构建语义空间A"></a>3. 基于KG/KB构建语义空间A</h3><h4 id="3-1-Zero-shot-Recognition-via-Semantic-Embeddings-and-Knowledge-Graphs"><a href="#3-1-Zero-shot-Recognition-via-Semantic-Embeddings-and-Knowledge-Graphs" class="headerlink" title="3.1 $Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs$"></a>3.1 $Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs$</h4><p>本文基于Graph COnvolution Network(GCN，一种处理Graph-structured数据的神经网络)引入Knowledge Graph的hierarchy结构进行计算。模型分为两个独立的部分，首先使用CNN-based方法（如resnet， Inception等）为输入的图片抽取特征向量，即CNN部分（图所示上方的CNN网络）；其次，GCN部分（图所示下方的GCN网络）将数据集中的每个class作为Graph中的一个节点，并对其做embedding表示输入GCN网络（即输入为有N个k为节点组成的N * k特征矩阵），通过神经网络每一层之间信息的传递和计算，为每个节点（class）输出一组权重向量（D维），即输出是一个N * D的特征矩阵。</p>
<p><img src="http://blog.openkg.cn/wp-content/uploads/2018/11/word-image-10.jpeg" alt="img"></p>
<p>模型训练时，Graph中seen class节点有来自CNN部分的图片特征向量作为监督信号（图所示绿色节点）训练GCN模型的参数；而测试时，Graph中的unseen class节点输出对应的权重向量，同时，与CNN部分对应图片输出的特征向量，最终得到分类的结果。</p>
<p>这里提及的Graph为克表示ImageNet class之间结构的WorldNet知识库，实验选取了其中一部分与ImageNet相关的子集</p>
<h4 id="3-2-Rethinking-Knowledge-Graph-Propagation-for-Zero-Shot-Learning"><a href="#3-2-Rethinking-Knowledge-Graph-Propagation-for-Zero-Shot-Learning" class="headerlink" title="3.2 $Rethinking Knowledge Graph Propagation for Zero-Shot Learning$"></a>3.2 $Rethinking Knowledge Graph Propagation for Zero-Shot Learning$</h4><p><a href="https://arxiv.org/pdf/1805.11724v1.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1805.11724v1.pdf</a></p>
<p>在1的基础上进行了改进，包括以下几个方面：</p>
<ul>
<li><p>更少的GCN层数，论文1中使用了6层神经网络进行训练，考虑到模型参数的优化问题，本文只使用了2层神经网络进行计算，即GPM</p>
</li>
<li><p>减少层数的同时，一些较远节点不被考虑在内，为了解决这个问题，作者将一些节点的祖先/子孙节点直接与该节点相连，生成了更密集的图，即DGPM；同时，这些直接相连的边按照距离的远近，加入attention机制进行了加权计算，即ADGPM</p>
</li>
<li><p>作者还提出了在CNN部分根据Graph信息进行fine tune的计算方式，使得提取图片特征的卷积网络可根据一些新出现的class进行更新</p>
</li>
</ul>
<p><strong>KG/KB相关论文列表：</strong></p>
<ul>
<li><ijcai-2018>Fine-grained Image Classification by Visual-Semantic Embedding</ijcai-2018></li>
<li><cvpr-2018>Multi-Label Zero-Shot Learning with Structured Knowledge Graphs</cvpr-2018></li>
<li><nips-2009>Zero-Shot Learning with Semantic Output Codes</nips-2009></li>
<li>少样本学习（Few-Shot Learning, FSL）</li>
</ul>
<p>前面 2.2 部分提到的论文，其迁移知识的方式主要是通过在语义空间构建 seen class 与 unseen class 之间的关系（下图左），而 Transductive Setting 则提出可通过 seen class 和 unseen class 的少量样本训练得到class之间的关联（下图右），即少样本学习（Few-ShotLearning, FSL）。</p>
<p><img src="http://blog.openkg.cn/wp-content/uploads/2018/11/word-image-13.jpeg" alt="img"></p>
<h3 id="FSL–Few-ShotLearning-少样本学习"><a href="#FSL–Few-ShotLearning-少样本学习" class="headerlink" title="FSL–Few-ShotLearning(少样本学习)"></a>FSL–Few-ShotLearning(少样本学习)</h3><h4 id="Learning-to-Compare-RelationNetwork-for-Few-Shot-Learning"><a href="#Learning-to-Compare-RelationNetwork-for-Few-Shot-Learning" class="headerlink" title="$Learning to Compare: RelationNetwork for Few-Shot Learning$"></a>$Learning to Compare: RelationNetwork for Few-Shot Learning$</h4><p><a href="https://arxiv.org/pdf/1711.06025.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1711.06025.pdf</a></p>
<p>本文从每个 class 中采样少量样本，作为参考样本（如下图左侧 5 张图片，分别代表 5 个 classes），以建立 class 之间的关系。本文所构建的 class relation 主要为相似关系，模型通过 embedding module 提取图片的特征向量，再分别将测试图片（下图所示袋鼠图片）的特征向量与参考样本的特征向量进行拼接输入 relation module，通过神经网络计算测试图片和参考样本图片之间的相似性，最终判断测试图片属于参考图片代表 class 的哪一类。</p>
<p><img src="http://blog.openkg.cn/wp-content/uploads/2018/11/word-image-15.jpeg" alt="img"></p>
<p><strong>FSL相关论文列表：</strong></p>
<ul>
<li><iclr-2018>Few-Shot Learning with Graph Neural Networks</iclr-2018></li>
<li><bigdata-2017>One-shot Learning for Fine-grained Relation Extraction via ConvolutionalSiamese Neural Network</bigdata-2017></li>
<li><nips-2016>Matching Networks for One Shot Learning</nips-2016></li>
<li><nips-2017>Prototypical Networks for Few-hot Learning</nips-2017></li>
<li><iclr-2017>Optimization as a model for few-shot learning</iclr-2017></li>
<li><icml-2016>Meta-learningwith Memory-augmented Neural Networks</icml-2016></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://woojoo520.github.io/2019/08/20/LeetCode-Day6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mariana">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Celery Fairy">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/20/LeetCode-Day6/" itemprop="url">LeetCode-Day6</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-20T20:51:45+08:00">
                2019-08-20
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="19-删除链表的倒数第N个节点"><a href="#19-删除链表的倒数第N个节点" class="headerlink" title="19. 删除链表的倒数第N个节点"></a>19. 删除链表的倒数第N个节点</h3><p>给定一个链表，删除链表的倒数第 n 个节点，并且返回链表的头结点。</p>
<p><strong>示例：</strong></p>
<blockquote>
<p>给定一个链表: 1-&gt;2-&gt;3-&gt;4-&gt;5, 和 n = 2.</p>
<p>当删除了倒数第二个节点后，链表变为 1-&gt;2-&gt;3-&gt;5.</p>
</blockquote>
<p>说明：</p>
<p>给定的 n 保证是有效的。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * struct ListNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode *next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) : val(x), next(NULL) &#123;&#125;</span></span><br><span class="line"><span class="comment"> * &#125;;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">removeNthFromEnd</span><span class="params">(ListNode* head, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        ListNode* temp = head;</span><br><span class="line">        ListNode* pre = head;</span><br><span class="line">        ListNode* after = head;</span><br><span class="line">        <span class="keyword">if</span>(head-&gt;next == <span class="literal">NULL</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; n;i++) &#123;</span><br><span class="line">            pre = pre-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(pre == <span class="literal">NULL</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> head-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span>(pre-&gt;next != <span class="literal">NULL</span>) &#123;</span><br><span class="line">            pre = pre-&gt;next;</span><br><span class="line">            after = after-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// ListNode* deleteNode = after-&gt;next;</span></span><br><span class="line">        <span class="comment">// delete deleteNode;</span></span><br><span class="line">        after-&gt;next = after-&gt;next-&gt;next;</span><br><span class="line">        <span class="keyword">return</span> head;    </span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>基本思路：就是固定两个指针，然后让pre指针先走n步，然后pre和after同时走，这样当pre到达最后的时候，after就是倒数第n个。</p>
<p>需要考虑的特殊情况：</p>
<ul>
<li>链表长度为1，只能删掉头结点，返回NULL</li>
<li>去掉的节点是头结点（即走完n步之后就是NULL），直接返回头结点的next</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://woojoo520.github.io/2019/08/19/LeetCode-Day5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mariana">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Celery Fairy">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/19/LeetCode-Day5/" itemprop="url">LeetCode-Day5</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-19T21:23:59+08:00">
                2019-08-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="17-电话号码的字母组合"><a href="#17-电话号码的字母组合" class="headerlink" title="17. 电话号码的字母组合"></a>17. 电话号码的字母组合</h3><p>给定一个仅包含数字 <code>2-9</code> 的字符串，返回所有它能表示的字母组合。</p>
<p>给出数字到字母的映射如下（与电话按键相同）。注意 1 不对应任何字母。</p>
<p><img src="https://assets.leetcode-cn.com/aliyun-lc-upload/original_images/17_telephone_keypad.png" alt="img"></p>
<p>示例:</p>
<p>输入：”23”<br>输出：[“ad”, “ae”, “af”, “bd”, “be”, “bf”, “cd”, “ce”, “cf”].<br>说明:<br>尽管上面的答案是按字典序排列的，但是你可以任意选择答案输出的顺序。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">combination</span><span class="params">(<span class="built_in">string</span> digits, <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">char</span>&gt; &gt;chars, <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp; ans, <span class="keyword">int</span> len, <span class="keyword">int</span> cur,<span class="keyword">int</span> nums[], <span class="keyword">int</span> sequence[], <span class="keyword">bool</span> isUsed[][<span class="number">4</span>])</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; nums[digits[cur] - <span class="string">'0'</span>];i++) &#123;</span><br><span class="line">            <span class="keyword">if</span>(isUsed[cur][i] == <span class="literal">false</span>) &#123;</span><br><span class="line">                isUsed[cur][i] = <span class="literal">true</span>;</span><br><span class="line">                <span class="built_in">vector</span>&lt;<span class="keyword">char</span>&gt; temp = chars[digits[cur] - <span class="string">'0'</span> - <span class="number">2</span>];</span><br><span class="line">                sequence[cur] = temp[i];</span><br><span class="line">                <span class="keyword">if</span>(cur == digits.length() - <span class="number">1</span>) &#123;</span><br><span class="line">                    <span class="built_in">string</span> str = <span class="string">""</span>;</span><br><span class="line">                    <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j &lt; digits.length();j++) &#123;</span><br><span class="line">                        str += sequence[j];</span><br><span class="line">                    &#125;</span><br><span class="line">                    ans.push_back(str);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    combination(digits, chars, ans, len, cur + <span class="number">1</span>, nums, sequence, isUsed);</span><br><span class="line">                &#125;</span><br><span class="line">                isUsed[cur][i] = <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; letterCombinations(<span class="built_in">string</span> digits) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; ans;</span><br><span class="line">        <span class="keyword">if</span>(digits.length() == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> ans;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">char</span>&gt; &gt;chars;</span><br><span class="line">        <span class="keyword">int</span> nums[<span class="number">10</span>] = &#123;<span class="number">0</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line">        <span class="keyword">int</span> index = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">2</span>;i &lt; <span class="number">10</span>;i++) &#123;</span><br><span class="line">            <span class="built_in">vector</span>&lt;<span class="keyword">char</span>&gt; temp;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j &lt; nums[i];j++, index++) &#123;</span><br><span class="line">                <span class="keyword">char</span> ch = <span class="string">'a'</span> + index;</span><br><span class="line">                temp.push_back(ch);</span><br><span class="line">            &#125;</span><br><span class="line">            chars.push_back(temp);</span><br><span class="line">        &#125;    </span><br><span class="line">        <span class="keyword">bool</span> isUsed[digits.length()][<span class="number">4</span>] = &#123;&#123;<span class="number">0</span>&#125;&#125;;</span><br><span class="line">        <span class="keyword">int</span> sequence[digits.length()] = &#123;<span class="number">0</span>&#125;;</span><br><span class="line">        combination(digits, chars, ans, digits.length(), <span class="number">0</span>, nums, sequence, isUsed);</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>主要是练习了一下回溯算法，技术还有待加强</p>
<p>今天也要加油鸭！</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://woojoo520.github.io/2019/08/19/物体检测/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mariana">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Celery Fairy">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/19/物体检测/" itemprop="url">物体检测</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-19T14:37:47+08:00">
                2019-08-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="物体检测"><a href="#物体检测" class="headerlink" title="物体检测"></a>物体检测</h2><h3 id="1-物体检测与图片分类的不同点："><a href="#1-物体检测与图片分类的不同点：" class="headerlink" title="1. 物体检测与图片分类的不同点："></a>1. 物体检测与图片分类的不同点：</h3><ul>
<li>图片分类器通常只需要输出对图片中的主物体的分类。但物体检测必须能够识别多个物体，即使有些物体可能在图片中不是占主要版面。严格来讲，这个任务一般叫<strong>多类物体检测</strong>，但绝大部分研究都是针对多类的设置，这里为了简单去掉了“多类”。</li>
<li>图片分类器只需要输出将图片识别成某类的概率，但物体检测不仅需要输出识别的概率，还需要识别物体在图片中的位置。这个通常是一个括住这个物体的方框，通常也被称之为<strong>边界框(bounding box)</strong></li>
</ul>
<h3 id="2-基于卷积神经网络的物体检测算法"><a href="#2-基于卷积神经网络的物体检测算法" class="headerlink" title="2. 基于卷积神经网络的物体检测算法"></a>2. 基于卷积神经网络的物体检测算法</h3><ul>
<li><h4 id="RCNN-https-arxiv-org-abs-1311-2524"><a href="#RCNN-https-arxiv-org-abs-1311-2524" class="headerlink" title="RCNN    https://arxiv.org/abs/1311.2524"></a>RCNN    <a href="https://arxiv.org/abs/1311.2524" target="_blank" rel="noopener">https://arxiv.org/abs/1311.2524</a></h4></li>
<li><h4 id="Fast-R-CNN-https-arxiv-org-abs-1504-08083"><a href="#Fast-R-CNN-https-arxiv-org-abs-1504-08083" class="headerlink" title="Fast R-CNN    https://arxiv.org/abs/1504.08083"></a>Fast R-CNN    <a href="https://arxiv.org/abs/1504.08083" target="_blank" rel="noopener">https://arxiv.org/abs/1504.08083</a></h4></li>
<li><h4 id="Faster-R-CNN-https-arxiv-org-abs-1506-01497"><a href="#Faster-R-CNN-https-arxiv-org-abs-1506-01497" class="headerlink" title="Faster R-CNN    https://arxiv.org/abs/1506.01497"></a>Faster R-CNN    <a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="noopener">https://arxiv.org/abs/1506.01497</a></h4></li>
<li><h4 id="Mask-R-CNN-https-arxiv-org-abs-1703-06870"><a href="#Mask-R-CNN-https-arxiv-org-abs-1703-06870" class="headerlink" title="Mask R-CNN    https://arxiv.org/abs/1703.06870"></a>Mask R-CNN    <a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="noopener">https://arxiv.org/abs/1703.06870</a></h4></li>
<li><h4 id="SSD-https-arxiv-org-abs-1512-02325"><a href="#SSD-https-arxiv-org-abs-1512-02325" class="headerlink" title="SSD    https://arxiv.org/abs/1512.02325"></a>SSD    <a href="https://arxiv.org/abs/1512.02325" target="_blank" rel="noopener">https://arxiv.org/abs/1512.02325</a></h4></li>
<li><h4 id="YOLO-https-arxiv-org-abs-1506-02640"><a href="#YOLO-https-arxiv-org-abs-1506-02640" class="headerlink" title="YOLO    https://arxiv.org/abs/1506.02640"></a>YOLO    <a href="https://arxiv.org/abs/1506.02640" target="_blank" rel="noopener">https://arxiv.org/abs/1506.02640</a></h4></li>
<li><h4 id="YOLOv2-https-arxiv-org-abs-1612-08242"><a href="#YOLOv2-https-arxiv-org-abs-1612-08242" class="headerlink" title="YOLOv2    https://arxiv.org/abs/1612.08242"></a>YOLOv2    <a href="https://arxiv.org/abs/1612.08242" target="_blank" rel="noopener">https://arxiv.org/abs/1612.08242</a></h4></li>
</ul>
<h3 id="3-具体介绍"><a href="#3-具体介绍" class="headerlink" title="3. 具体介绍"></a>3. 具体介绍</h3><h4 id="3-1-R-CNN-区域卷积神经网络"><a href="#3-1-R-CNN-区域卷积神经网络" class="headerlink" title="3.1 R-CNN(区域卷积神经网络)"></a>3.1 R-CNN(区域卷积神经网络)</h4><p>这是一个基于卷积神经网络的物体检测的奠基之作。其核心思想是在对每张图片选取多个区域，然后每个区域作为一个样本进入一个卷积神经网络来抽取特征，最后使用分类器来对其进行分类，和一个回归器来得到准确的边框。</p>
<p><img src="C:%5CUsers%5C12751%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1566198219445.png" alt="1566198219445"></p>
<p>具体来说，这个算法有如下几个步骤：</p>
<ul>
<li>对每张输入图片使用一个基于规则的“选择型搜索”算法来选取多候选区域</li>
<li>跟微调迁移学习里那样，选取一个预先训练好的神经网络并去掉最后一个输入层。每个区域被调整成整个网络要求的输入大小并计算输出。这个输出将作为这个区域的特征。</li>
<li>使用这些区域特征训练多个SVM来做物体识别，每个SVM预测一个区域是不是包含某个物体</li>
<li>使用这些区域特征来训练线性回归器将候选区域</li>
</ul>
<p>直观上R-CNN很好理解，但<strong>问题是它可能特别慢</strong>。一张图片我们可能选出上千个区域，导致一张图片需要做上千次预测。虽然跟微调不一样，这里训练可以不用更新用来抽特征的卷积神经网络，从而我们可以事先算好每个区域的特征并保存。但对于预测，我们无法避免这个。从而导致R-CNN很难在十几种被使用</p>
<h4 id="3-2-Fast-R-CNN-快速的区域卷积神经网络"><a href="#3-2-Fast-R-CNN-快速的区域卷积神经网络" class="headerlink" title="3.2 Fast R-CNN(快速的区域卷积神经网络)"></a>3.2 Fast R-CNN(快速的区域卷积神经网络)</h4><p>Fast-RCNN对R-CNN主要做了两点改进来提升性能</p>
<ul>
<li>考虑到<strong>R-CNN里面的大量区域可能是相互覆盖</strong>，每次重新抽取特征过于浪费。因此<strong>Fast R-CNN先对输入图片抽取特征，然后再选取区域</strong></li>
<li>代替R-CNN使用多个SVM来做分类，Fast-RCNN使用单个多类逻辑回归，这也是前面教程里默认使用的</li>
</ul>
<p><img src="C:%5CUsers%5C12751%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1566201897248.png" alt="1566201897248"></p>
<p>从示意图中可以看到，使用选择型搜索选取的区域是作用在卷积神经网络提取的特征上。这样我们只需要对原始的输入图片做一次特征提取即可，如此节省了大量重复计算。</p>
<p>Fast R-CNN提出<strong>特征区域池化层（Region of Interest(RoI) Pooling）</strong>，它的输入为特征和一系列的区域，对每个区域它将其均匀划分成n * m的小区域，并对每个小区域做最大池化，从而得到一个n * m的输出。因此不管输入区域的大小，RoI池化层都将其池化成固定大小输出。</p>
<p>下面，详细的来看一下ROI Pooling：</p>
<p>ROIs Pooling顾名思义，是Pooling层的一种，而且是针对RoIs的Pooling，它的特点是<strong>输入特征图尺寸不固定，但是输出特征图尺寸固定</strong>。</p>
<ul>
<li>在Fast R-CNN中，RoI是指Selective Search完成后得到的“候选框”在特征图上的映射，如下图所示</li>
<li>在Faster R-CNN中，候选框是经过RPN产生的，然后再把各个“候选框”映射到特征图上，得到RoIs</li>
</ul>
<p><img src="https://img-blog.csdn.net/20180119150020632?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGFucmFuMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p>图1 Fast R-CNN整体结构</p>
<p><strong>ROI Pooling的输入：</strong></p>
<ul>
<li><strong>特征图：</strong>指的是图1中所示的特征图，在Fast R-CNN中，它位于RoI Pooling之前，在Faster RCNN中，它是与RPN共享的那个特征图，通常我们称之为“share_conv”</li>
<li><strong>rois：</strong>在Fast R-CNN中，指的是Selective Search的输出；在Faster R-CNN中指的是RPN的输出，一堆矩形候选框框，形状为1 * 5 * 1 * 1 (4个坐标+索引index)，其中值得注意的是：<strong>坐标的参考系</strong>不是针对feature map这张图的，而<strong>是针对原图的（神经网络最开始的输入）</strong></li>
</ul>
<p><strong>ROI Pooling的输出：</strong></p>
<p>输出是batch个vector，其中batch的值等于RoI的个数，vector的大小为channel * w * h；RoI Pooling的过程就是将一个个大小不同的box矩形框，都映射成大小固定（w * h）的矩形框</p>
<p><strong>ROI Pooling的过程：</strong></p>
<ul>
<li>根据输入image，将RoI映射到feature map对应位置</li>
<li>将映射后的区域划分为相同大小的sections（sections数量与输出的维度相同）</li>
<li>对每个sections进行max pooling操作</li>
</ul>
<p>这样我们就可以从不同大小的方框得到固定大小的相应的feature maps。值得一提的是，输出的feature maps的大小不取决与ROI和卷积feature maps的大小。ROI Pooling最大的好处就在于极大地提高了处理速度</p>
<p><strong>Example：</strong></p>
<p>考虑一个8 * 8大小的feature map，一个ROI，以及输出大小为2 * 2</p>
<p>1）输入固定大小的feature map</p>
<p><img src="https://img-blog.csdn.net/20171112193549325?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvQVVUTzE5OTM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img"></p>
<p>2）region proposal投影之后位置（左上角，右下角坐标）：（0，3），（7，8）</p>
<p><img src="https://img-blog.csdn.net/20171112193608750?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvQVVUTzE5OTM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img"></p>
<p>3）将其划分为（2 * 2）个sections（因为输出大小为2 * 2），我们可以得到：</p>
<p><img src="https://img-blog.csdn.net/20171112193628721?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvQVVUTzE5OTM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img"></p>
<p>4）对每个section做max pooling，可以得到</p>
<p><img src="https://img-blog.csdn.net/20171112193709781?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvQVVUTzE5OTM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img"></p>
<p>Faster R-CNN</p>
<p>Fast R-CNN沿用了R-CNN的选择型搜索方法来选择区域，这个通常很慢。Faster R-CNN做的主要改进就是提出了<strong>区域候选网络（Region Proposal Network, RPN）</strong>来代替选择型搜索。</p>
<p>它是这么工作的：</p>
<ul>
<li>在输入特征上放置一个填充为1通道是256 的3 * 3卷积。这样，连同他的周围8个像素，都被映射成一个长为256的向量</li>
<li>以对每个像素为中心生成数个大小和长宽比预先设计好的k个默认框，通常也叫做锚框</li>
<li>对每个边框，使用其中心像素对应的256维向量作为特征，RPN训练一个2类分类器来判断这个区域是不是含有任何感兴趣的物体还是只是背景，和一个4位输出的回归分类器来预测一个更准确的边框</li>
<li>对于所有的锚框，个数为n m k，如果输入大小是n * m, 选出被判断成还有物体的，然后对他们对应的回归器预测的边框作为输入放进接下来的RoI池化层</li>
</ul>
<p>虽然看上去有些复杂，但RPN思想非常直观。首先候选预先配置好的一些区域，然后通过神经网络来判断这些区域是不是感兴趣的。如果是，那么再预测一个更加准确的边框。这样我们能有效降低搜索任何形状的边框的代价。</p>
<p><strong>Faster R-CNN的RPN详解：</strong></p>
<ul>
<li><p>anchors：特征可以看做一个尺度51<em>39的256通道图像，对于该图像的每一个位置，考虑9个可能的候选窗口：三种面积{128,256,512}×{128,256,512}×三种比例{1:1,1:2,2:1}{1:1,1:2,2:1}。这些候选窗口称为anchors。下图示出51</em>39个anchor中心，以及9种anchor示例。</p>
<p>特征可以看做一个尺度51<em>39的256通道图像，对于该图像的每一个位置，考虑9个可能的候选窗口：三种面积{128,256,512}×{128,256,512}×三种比例{1:1,1:2,2:1}{1:1,1:2,2:1}。这些候选窗口称为anchors。下图示出51</em>39个anchor中心，以及9种anchor示例。<br><img src="C:%5CUsers%5C12751%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1566260296023.png" alt="1566260296023"></p>
</li>
<li><p>SOFTMAX的两支</p>
<p><img src="C:%5CUsers%5C12751%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1566260328221.png" alt="1566260328221"></p>
<p> 计算每个像素256-d的9个尺度下的值，得到9个anchor，我们给每个anchor分配一个二进制的标签（前景背景）。我们分配正标签前景给两类anchor：1）与某个ground truth（GT）包围盒有最高的IoU重叠的anchor（也许不到0.7），2）与任意GT包围盒有大于0.7的IoU交叠的anchor。注意到一个GT包围盒可能分配正标签给多个anchor。我们分配负标签（背景）给与所有GT包围盒的IoU比率都低于0.3的anchor。非正非负的anchor对训练目标没有任何作用，由此输出维度为（2*9）18，一共18维。</p>
<p>假设在conv5 feature map中每个点上有k个anchor（默认k=9），而每个anhcor要分foreground和background，所以每个点由256d feature转化为cls=2k scores；而每个anchor都有[x, y, w, h]对应4个偏移量，所以reg=4k coordinates</p>
<p>补充一点，全部anchors拿去训练太多了，训练程序会在合适的anchors中随机选取128个postive anchors+128个negative anchors进行训练。<br><strong>以上是传统的RPN，下面是Faster R-CNN 的RPN部分</strong>。</p>
</li>
<li><p><strong>bounding box regression</strong></p>
<p>前2.）中已经计算出foreground anchors，使用bounding box regression回归得到预设anchor-box到ground-truth-box之间的变换参数，即平移（dx和dy）和伸缩参数（dw和dh），由此得到初步确定proposal。</p>
</li>
</ul>
<p>  如图9所示绿色框为飞机的Ground Truth(GT)，红色为提取的foreground anchors，那么即便红色的框被分类器识别为飞机，但是由于红色的框定位不准，这张图相当于没有正确的检测出飞机。所以我们希望采用一种方法对红色的框进行微调，使得foreground anchors和GT更加接近。<br>  <img src="C:%5CUsers%5C12751%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1566260396876.png" alt="1566260396876"></p>
<p>  对于窗口一般使用四维向量(x, y, w, h)表示，分别表示窗口的中心点坐标和宽高。对于图 10，红色的框A代表原始的Foreground Anchors，绿色的框G代表目标的GT，我们的目标是寻找一种关系，使得输入原始的anchor A经过映射得到一个跟真实窗口G更接近的回归窗口G’，即：给定A=(Ax, Ay, Aw, Ah)，寻找一种映射f，使得f(Ax, Ay, Aw, Ah)=(G’x, G’y, G’w, G’h)，其中(G’x, G’y, G’w, G’h)≈(Gx, Gy, Gw, Gh)。<br>  <img src="C:%5CUsers%5C12751%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1566260415053.png" alt="1566260415053"></p>
<p>  那么经过何种变换才能从图6中的A变为G’呢？ 比较简单的思路就是:</p>
<ol>
<li><p>先做平移</p>
<p><img src="C:%5CUsers%5C12751%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1566260462344.png" alt="1566260462344"></p>
</li>
<li><p>再做缩放</p>
<p><img src="C:%5CUsers%5C12751%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1566260476062.png" alt="1566260476062"></p>
<p>观察上面4个公式发现，需要学习的是dx(A)，dy(A)，dw(A)，dh(A)这四个变换。当输入的anchor与GT相差较小时，可以认为这种变换是一种线性变换， 那么就可以用线性回归来建模对窗口进行微调（注意，只有当anchors和GT比较接近时，才能使用线性回归模型，否则就是复杂的非线性问题了）。对应于Faster RCNN原文，平移量(tx, ty)与尺度因子(tw, th)如下：</p>
</li>
</ol>
<p>  接下来的问题就是如何通过线性回归获得dx(A)，dy(A)，dw(A)，dh(A)了。线性回归就是给定输入的特征向量X, 学习一组参数W, 使得经过线性回归后的值跟真实值Y（即GT）非常接近，即Y=WX。对于该问题，输入X是一张经过卷积获得的feature map，定义为Φ；同时还有训练传入的GT，即(tx, ty, tw, th)。输出是dx(A)，dy(A)，dw(A)，dh(A)四个变换。那么目标函数可以表示为：$d_{<em>}(P) = w_{</em>}^T \phi_{s}(P)$ </p>
<p>  其中Φ(A)是对应anchor的feature map组成的特征向量，w是需要学习的参数，d(A)是得到的预测值（*表示 x，y，w，h，也就是每一个变换对应一个上述目标函数）。为了让预测值(tx, ty, tw, th)与真实值最小，得到损失函数：</p>
<p>  $Loss = \sum_{i}^{N}(t_{<em>}^{i} - w_{</em>}^{T} \phi_{s}(P^{i})^2)$</p>
<p>  函数优化目标为：<img src="C:%5CUsers%5C12751%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1566260749902.png" alt="1566260749902"></p>
<ul>
<li><p>将预proposal利用feat_stride和im_info将anchors映射回原图，判断预proposal是否大范围超过边界，剔除严重超出边界的。</p>
<p>按照softmax score进行从大到小排序，提取前2000个预proposal，对这个2000个进行NMS(非极大值抑制)，将得到的再次进行排序，输出300个proposal。</p>
</li>
</ul>
<p><strong>NMS（非极大抑制致）</strong></p>
<p>由于锚点经常重叠，因此候选框最终也会在同一个目标上重叠。为了解决重复候选框的问题，我们使用一个简单的泛，称为非极大抑制(NMS)。NMS获取按照分数排序的候选列表并对已排序的列表进行迭代，丢弃那些IoU值大于某个预定义阈值的候选框，并提出一个具有更高分数的候选框。总之，抑制的过程是一个迭代-遍历-消除的过程，如下图所示：</p>
<ul>
<li><p>将所有候选框的得分进行排序，选中最高分及其所对应的框</p>
<p><img src="C:%5CUsers%5C12751%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1566260974214.png" alt="1566260974214"></p>
<p><img src="C:%5CUsers%5C12751%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1566260986791.png" alt="1566260986791"></p>
</li>
<li><p>遍历其余的框，如果它和当前最高得分框的重叠面积大于一定的阈值，我们将其删除</p>
<p><img src="C:%5CUsers%5C12751%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1566261025214.png" alt="1566261025214"></p>
</li>
<li><p>从没有处理的框中继续选择一个得分最高的，重复上述过程。</p>
</li>
</ul>
<h4 id="Mask-R-CNN"><a href="#Mask-R-CNN" class="headerlink" title="Mask R-CNN"></a>Mask R-CNN</h4><p>Mask R-CNN在Faster R-CNN上加入了一个新的像素级别的预测层，它不仅对一个锚框预测它对应的类和真实的边框，而且他会判断这个锚框类每个像素对应的那个物体还是只是背景。后者是语义分割要解决的问题。Mask R-CNN使用了全连接卷积网络（FCN）来完成这个预测。当然这也意味着训练数据必须有像素级别的标注，而不是简单的边框。</p>
<p><img src="C:%5CUsers%5C12751%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1566264201349.png" alt="1566264201349"></p>
<p>因为FCN会精确预测每个像素的类别，就是输入图片中的每个像素都会在标注中对应一个类别。对于输入图片中的一个锚框，我们可以精确的匹配到像素标注中对应的区域。但是PoI池化是作用在卷积之后的特征上，其默认是将锚框做了定点化。例如假设选择的锚框是( x , y , w , h ) ，且特征抽取将图片变小了16倍，就是如果原始图片是256 × 256 ，那么特征大小就是16 × 16 。这时候在特征上对应的锚框就是变成了( ⌊ x / 16 ⌋ , ⌊ y / 16 ⌋ , ⌊ w / 16 ⌋ , ⌊ h / 16 ⌋ ) 。如果x , y , w , h 中有任何一个不被16整除，那么就可能发生错位。同样道理，在上面的样例中我们看到，如果锚框的长宽不被池化大小整除，那么同样会定点化，从而带来错位。</p>
<p>通常这样的错位只是在几个像素之间，对于分类和边框预测影响不大。但对于像素级别的预测，这样的错位可能会带来大问题。Mask R-CNN提出一个RoI Align层，它类似于RoI池化层，但是去除掉了定点化步骤，就是移除了所有⌊ ⋅ ⌋ 。如果计算得到的表框不是刚好在像素之间，那么我们就用四周的像素来线性插值得到这个点上的值。</p>
<h4 id="SSD：单发多框检测器"><a href="#SSD：单发多框检测器" class="headerlink" title="SSD：单发多框检测器"></a>SSD：单发多框检测器</h4><p>在R-CNN系列的模型里面。区域候选和分类是分作两块来进行的。SSD则将其统一成一个步骤来使得模型更加简单并且速度更快。</p>
<p>它跟Faster R-CNN主要有两点不一样：</p>
<ul>
<li><p>对于锚框，我们不再首先判断它是不是含有感兴趣物体，再将正类锚框放入真正物体分类。SSD里我们直接使用一个num_class+1类分类器来判断它对应的是哪类物体，还是只是背景。我们也不再有额外的回归器对边框再进一步预测，而是直接使用单个回归器来预测真实边框。</p>
</li>
<li><p>SSD不只是对卷积神经网络输出的特征做预测，它会进一步将特征通过卷积和池化层变小来做预测。这样达到多尺度预测的效果</p>
<p><img src="C:%5CUsers%5C12751%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1566264662752.png" alt="1566264662752"></p>
</li>
</ul>
<h4 id="YOLO：只需要看一遍"><a href="#YOLO：只需要看一遍" class="headerlink" title="YOLO：只需要看一遍"></a>YOLO：只需要看一遍</h4><p>不管是Faster R-CNN还是SSD， 他们声称的锚框仍然有大量是重叠的，从而导致仍然有大量的区域被重复计算了。YOLO试图来解决这个问题。它将图片特征均匀的切成S * S块，每一块当做一个锚框。每个锚框预测B个框，以及这个锚框主要包含哪个物体。</p>
<p><img src="C:%5CUsers%5C12751%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1566264803189.png" alt="1566264803189"></p>
<h4 id="YOLO-v2：更好，更快，更强"><a href="#YOLO-v2：更好，更快，更强" class="headerlink" title="YOLO v2：更好，更快，更强"></a>YOLO v2：更好，更快，更强</h4><p>YOLO v2 对WOLO进行一些改进的地方，其主要包括：</p>
<ul>
<li><p>使用更好的卷积神经网络来做特征提取，使用更大输入图片448 * 448 使得特征输出大小增大到13 * 13</p>
</li>
<li><p>不再使用均匀切割的锚框，而是对训练数据里的真实锚框做聚类，然后使用聚类中心作为锚框。相对于SSD 和Faster R-CNN来说可以大幅降低锚框的个数</p>
</li>
<li><p>不再使用YOLO的全连接层来预测，而是同SSD一样使用卷积。例如假设使用5个锚框（聚类为5类），那么物体分类使用通道数是 5 * (1 + num_classes)的1 * 1卷积，边框回归使用通道数为4 * 5</p>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://woojoo520.github.io/2019/08/19/LeetCode-Day4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mariana">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Celery Fairy">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/19/LeetCode-Day4/" itemprop="url">LeetCode-Day4</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-19T09:10:55+08:00">
                2019-08-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="14-最长公共前缀"><a href="#14-最长公共前缀" class="headerlink" title="14. 最长公共前缀"></a>14. 最长公共前缀</h3><p>编写一个函数来查找字符串数组中的最长公共前缀。</p>
<p>如果不存在公共前缀，返回空字符串 “”。</p>
<p>示例 1:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: [&quot;flower&quot;,&quot;flow&quot;,&quot;flight&quot;]</span><br><span class="line">输出: &quot;fl&quot;</span><br></pre></td></tr></table></figure>

<p>示例 2:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入: [&quot;dog&quot;,&quot;racecar&quot;,&quot;car&quot;]</span><br><span class="line">输出: &quot;&quot;</span><br><span class="line">解释: 输入不存在公共前缀。</span><br></pre></td></tr></table></figure>

<p><strong>说明:</strong></p>
<p>所有输入只包含小写字母 a-z 。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">longestCommonPrefix</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp; strs)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(strs.empty()) <span class="keyword">return</span> <span class="string">""</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j&lt;strs[<span class="number">0</span>].size(); j++)</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i&lt;strs.size(); i++)</span><br><span class="line">                <span class="keyword">if</span>(j&gt;strs[i].size() || strs[<span class="number">0</span>][j] != strs[i][j])</span><br><span class="line">                    <span class="keyword">return</span> strs[i].substr(<span class="number">0</span>,j);</span><br><span class="line">        <span class="keyword">return</span> strs[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>解释：</p>
<p>如果strs的长度为0，直接返回“”</p>
<p>然后同时遍历每个字母的第一个字符，第二个字符…直到遇到不相等的就直接返回。</p>
<h3 id="15-三数之和"><a href="#15-三数之和" class="headerlink" title="15. 三数之和"></a>15. 三数之和</h3><p>给定一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？找出所有满足条件且不重复的三元组。</p>
<p>注意：答案中不可以包含重复的三元组。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">例如, 给定数组 nums = [-1, 0, 1, 2, -1, -4]，</span><br><span class="line"></span><br><span class="line">满足要求的三元组集合为：</span><br><span class="line">[</span><br><span class="line">  [-1, 0, 1],</span><br><span class="line">  [-1, -1, 2]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p><strong>解题方案：</strong></p>
<ul>
<li>首先对数组进行排序， 排序后固定一个数nums[i]，再使用左右指针指向nums[i]后面的两端，数字分别为nums[L]和nums[R]， 计算三个数的和sum，判断是否满足为0，满足则添加进结果集</li>
<li>如果nums[i] 大于0，则三数之和必然无法等于0，结束循环</li>
<li>如果nums[i] == nums[i - 1]，则说明该数字重复，会导致结果重复，所以应该跳过</li>
<li>当sum == 0时，nums[L] == nums[L + 1]则会导致结果重复，应该跳过,L++</li>
<li>当sum == 0时，nums[R] == nums[R - 1]时会导致结果重复，应该跳过，R–</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; threeSum(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums) &#123;</span><br><span class="line">        sort(nums.begin(), nums.end());</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; ans;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; nums.size() &amp;&amp; nums[i] &lt;= <span class="number">0</span>;i++) &#123;</span><br><span class="line">            <span class="keyword">if</span>(i == <span class="number">0</span> || nums[i] &gt; nums[i - <span class="number">1</span>]) &#123;</span><br><span class="line">                <span class="keyword">int</span> l = i + <span class="number">1</span>;</span><br><span class="line">                <span class="keyword">int</span> r = nums.size() - <span class="number">1</span>;</span><br><span class="line">                <span class="keyword">while</span>(l &lt; r) &#123;</span><br><span class="line">                    <span class="keyword">int</span> sum = nums[i] + nums[l] + nums[r];</span><br><span class="line">                    <span class="keyword">if</span>(sum == <span class="number">0</span>) &#123;</span><br><span class="line">                        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp;</span><br><span class="line">                        temp.push_back(nums[i]);</span><br><span class="line">                        temp.push_back(nums[l]);</span><br><span class="line">                        temp.push_back(nums[r]);</span><br><span class="line">                        ans.push_back(temp);</span><br><span class="line">                        l += <span class="number">1</span>;</span><br><span class="line">                        r -= <span class="number">1</span>;</span><br><span class="line">                        <span class="keyword">while</span>(l &lt; r &amp;&amp; nums[l] == nums[l - <span class="number">1</span>]) &#123;</span><br><span class="line">                            l++;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">while</span>(l &lt; r &amp;&amp; nums[r] == nums[r + <span class="number">1</span>]) &#123;</span><br><span class="line">                            r--;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125; <span class="keyword">else</span> <span class="keyword">if</span>(sum &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                        l++;</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        r--;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ans;    </span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>


          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://woojoo520.github.io/2019/08/17/LeetCode-Day3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mariana">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Celery Fairy">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/17/LeetCode-Day3/" itemprop="url">LeetCode-Day3</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-17T21:44:01+08:00">
                2019-08-17
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="11-盛最多水的容器"><a href="#11-盛最多水的容器" class="headerlink" title="11. 盛最多水的容器"></a>11. 盛最多水的容器</h3><p>给定 n 个非负整数 a1，a2，…，an，每个数代表坐标中的一个点 (i, ai) 。在坐标内画 n 条垂直线，垂直线 i 的两个端点分别为 (i, ai) 和 (i, 0)。找出其中的两条线，使得它们与 x 轴共同构成的容器可以容纳最多的水。</p>
<p>说明：你不能倾斜容器，且 n 的值至少为 2</p>
<p><img src="https://aliyun-lc-upload.oss-cn-hangzhou.aliyuncs.com/aliyun-lc-upload/uploads/2018/07/25/question_11.jpg" alt="img"></p>
<p><strong>示例:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: [1,8,6,2,5,4,8,3,7]</span><br><span class="line">输出: 49</span><br></pre></td></tr></table></figure>

<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">maxArea</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; height)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> len = height.size();</span><br><span class="line">        <span class="keyword">int</span> left = <span class="number">0</span>, right = len - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> max = <span class="number">0</span>, temp = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> minHeight;</span><br><span class="line">        <span class="keyword">while</span>(left != right) &#123;</span><br><span class="line">            minHeight = height[left] &lt; height[right] ? height[left++] : height[right--];</span><br><span class="line">            temp = minHeight * (right - left + <span class="number">1</span>);</span><br><span class="line">            <span class="keyword">if</span>(temp &gt; max) &#123;</span><br><span class="line">                max = temp;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> max;  </span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>解释：</p>
<p>这里采用的是<strong>双指针法</strong></p>
<p>这种方法背后的思路在于，两线段之间形成的区域总是会受到较短的那条长度的限制。此外，两条线段距离越远，得到的面积就会越大。</p>
<p>所以，我们在由线段构成的数组中使用两个指针，一个放在开始，一个放在末尾。此外，我们会使用变量 max 来持续存储到目前为止所获得的最大面积。 在每一步中，我们会找出指针所指向的两条线段形成的区域，更新 max，并将指向较短线段的指针向较长线段那端移动一步。</p>
<p><img src="https://pic.leetcode-cn.com/Figures/11_Container_WaterSlide1.PNG" alt="img"></p>
<p>这种方法如何工作？</p>
<p>最初我们考虑由最外围两条线段构成的区域。现在，为了使面积最大化，我们需要考虑更长的两条线段之间的区域。如果我们试图将指向较长线段的指针向内侧移动，矩形区域的面积将受限于较短的线段而不会获得任何增加。但是，在同样的条件下，移动指向较短线段的指针尽管造成了矩形宽度的减小，但却可能会有助于面积的增大。因为移动较短线段的指针会得到一条相对较长的线段，这可以克服由宽度减小而引起的面积减小。</p>
<h3 id="12-整数转罗马数字"><a href="#12-整数转罗马数字" class="headerlink" title="12.整数转罗马数字"></a>12.整数转罗马数字</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">intToRoman</span><span class="params">(<span class="keyword">int</span> num)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> values[] = &#123;<span class="number">1000</span>, <span class="number">900</span>, <span class="number">500</span>, <span class="number">400</span>, <span class="number">100</span>, <span class="number">90</span>, <span class="number">50</span>, <span class="number">40</span>, <span class="number">10</span>, <span class="number">9</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">1</span>&#125;;</span><br><span class="line">        <span class="built_in">string</span> reps[] = &#123;<span class="string">"M"</span>, <span class="string">"CM"</span>, <span class="string">"D"</span>, <span class="string">"CD"</span>, <span class="string">"C"</span>, <span class="string">"XC"</span>, <span class="string">"L"</span>, <span class="string">"XL"</span>, <span class="string">"X"</span>, <span class="string">"IX"</span>, <span class="string">"V"</span>, <span class="string">"IV"</span>, <span class="string">"I"</span>&#125;;</span><br><span class="line">        <span class="built_in">string</span> res;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">13</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">while</span>(num &gt;= values[i]) &#123;</span><br><span class="line">                num -= values[i];</span><br><span class="line">                res += reps[i];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;        </span><br><span class="line">        <span class="keyword">return</span> res; </span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>


          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://woojoo520.github.io/2019/08/17/LeetCode-Day2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mariana">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Celery Fairy">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/17/LeetCode-Day2/" itemprop="url">LeetCode-Day2</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-17T21:43:47+08:00">
                2019-08-17
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>今天主要学习了int的最大范围的表示</p>
<p>$ -2^{31} &lt; int &lt; 2^{31} - 1$</p>
<p>min表示为<code>-(1 &lt;&lt; 31)</code></p>
<p>max表示为<code>(1 &lt;&lt; 31) - 1</code></p>
<p>这里需要注意的是<code>&lt;&lt;</code>移位运算符的优先级比较低，不可以写成<code>1 &lt;&lt; 31 - 1</code>，会被理解为<code>1 &lt;&lt; (31 - 1)</code>，即<code>1 &lt;&lt;30</code></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://woojoo520.github.io/2019/08/17/HDR的简单介绍/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mariana">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Celery Fairy">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/17/HDR的简单介绍/" itemprop="url">HDR的简单介绍</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-17T08:57:27+08:00">
                2019-08-17
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="HDR"><a href="#HDR" class="headerlink" title="HDR"></a>HDR</h2><h3 id="HDR的简介"><a href="#HDR的简介" class="headerlink" title="HDR的简介"></a>HDR的简介</h3><p><strong>HDR——High-Dynamic Range（高动态光照渲染）</strong>，相比普通的图像，可以提供更多的动态范围和图像细节，根据不同的曝光时间的LDR(Low-Dynamic Range)图像，利用曝光时间相对应最佳细节的LDR图像来合成最终的HDR图像，能够更好的反映出真实环境中的视觉效果。</p>
<p>说白了，就是一张图片尽可能得同时显示最亮和最暗的地方，或者说是让亮的地方更亮，让暗的地方更暗（或者理解为<strong>能够大幅提高画面细节的明暗对比度</strong>）。HDR显示下的色彩更接近人眼真实的感知，所以HDR提供更逼真，更身临其境的电影、游戏和内容创作体验。</p>
<p>人眼的视觉是目前最强大的摄影器材跟显像设备，我们不断升级的摄影跟显示器设备都是为了还原人眼所见，以求达到所见即所得的效果。</p>
<h3 id="HDR的组成"><a href="#HDR的组成" class="headerlink" title="HDR的组成"></a>HDR的组成</h3><p>HDR由两部分组成：<strong>动态曝光控制</strong>和<strong>光晕效果</strong>。</p>
<h4 id="动态曝光控制"><a href="#动态曝光控制" class="headerlink" title="动态曝光控制"></a>动态曝光控制</h4><p>通常，显示器能够显示R、G、B分量在[0, 255]之间的像素值。而256个不同的亮度级别显然不能表示自然界中光线的亮度情况。举个例子，太阳的亮度是白炽灯亮度的几千倍或者被漫反射照亮的室内亮度的几万倍，这远远超出了显示器的亮度表示能力。HDR技术所要解决的问题就是在有限的亮度范围内表示出宽广的亮度范围。原理类似于照相机的曝光功能，通过算法调整光线亮度，将光线从高动态范围映射到低动态范围，从而得到令人信服的光照效果</p>
<h4 id="光晕效果"><a href="#光晕效果" class="headerlink" title="光晕效果"></a>光晕效果</h4><p>人从暗处走到光亮的地方，瞳孔由于来不及收缩，眼睛会自己眯起来，以保护视网膜上的感光细胞。HDR通过对原始图像进行调整，可以模拟这种人眼自动适应光线变化的胜利反应，产生类似于光晕的效果</p>
<p>图像经DHR处理后的理想效果是亮处足够耀眼，暗处能够分辨物体的轮廓与深度，而非原图的一团漆黑。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://woojoo520.github.io/2019/08/16/DCNN-trick/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mariana">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Celery Fairy">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/16/DCNN-trick/" itemprop="url">DCNN-trick</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-16T07:36:47+08:00">
                2019-08-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="深度神经网络中的实现细节（技巧Or提示）"><a href="#深度神经网络中的实现细节（技巧Or提示）" class="headerlink" title="深度神经网络中的实现细节（技巧Or提示）"></a>深度神经网络中的实现细节（技巧Or提示）</h2><h3 id="1-数据增强"><a href="#1-数据增强" class="headerlink" title="1. 数据增强"></a>1. 数据增强</h3><p>由于深度网络需要在大量训练图像上进行训练以获得令人满意的性能，如果原始图像数据集包含有限的训练图像，则最好进行数据增强以提高性能。此外，数据扩充称为培训深层网络时必须要做的事情。</p>
<ul>
<li>有许多方法可以进行数据增强，例如流行的<strong>水平翻转</strong>，<strong>随机裁剪</strong>和<strong>颜色抖动</strong>。此外，还可以尝试许多不同处理的组合，例如同时进行旋转和放缩。此外，还可以尝试将所有色素的饱和度 和 值（HSV颜色空间中的S和V的分量）提高到0.25到4之间的power（对于补丁中的所有像素都相同），将这些值乘以0.7~1.4之间的系数，并且加上一个介于-0.1到0.1之间的值。此外，还可以在[-0.1, 0.1]之间添加一个值到图像/补丁中所有像素的H值（HSV的H分量）</li>
<li>Krizhevsky等人在训练著名的Alex-Net时提出了$Fancy PCA$。$Fancy PCA$改变了训练图像中的RGB通道的强度。实际上，可以在整个训练图像中首先对RGB像素值集执行PCA。然后，对于每一个训练图像，只添加以下量的每个RGB图像的像素（例如： $I_{xy}=[I_{xy}^R, I_{xy}^G, I_{xy}^B]^{T}] : [P_{1}, P_{2}, P_{3}] [\alpha_{1} \lambda_{1}, \alpha_{2} \lambda_{2}, \alpha_{3} \lambda_{3}]^{T}$），其中$P_{i}$ 和$\lambda_{i}$分别是RGB像素值的3 * 3协方差矩阵的第 i 个本征向量和特征值，$\alpha_{i}$是具有平均值0和标准差0.1的高斯绘制的随机变量。请注意，每个$\alpha_{i}$仅针对特定训练图像的所有像素绘制一次，直到该图像再次用于训练。也就是说，当模型再次遇到相同的训练图像时，它会随机产生另一个$\alpha_{i}$用于数据增强。在<code>ImageNet Classification with Deep Convolutional
Neural Networks</code>中，他们声称<code>Fancy PCA</code>可以近似捕获自然图像的重要特性，即物体特性对于照明强度和颜色的变化是不变的。对于分类性能，该方案在ImageNet 2012的竞争中将前1个错误率降低了1%以上。</li>
</ul>
<h3 id="2-对图像进行预处理"><a href="#2-对图像进行预处理" class="headerlink" title="2. 对图像进行预处理"></a>2. 对图像进行预处理</h3><p>现在我们已经获得了大量的训练样本（图像/作物），但是不要着急。实际上，有必要对这些图像进行预处理。介绍下列几种预处理方法：</p>
<ul>
<li><p><code>zero-center the data, and then normalize them</code>，在Python中就是以下两行代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X -= np.mean(X, axis=<span class="number">0</span>)	<span class="comment"># zero-center</span></span><br><span class="line">X /= np.std(X, axis=<span class="number">0</span>)	<span class="comment"># normalize</span></span><br></pre></td></tr></table></figure>

<p>其中，X是输入数据。该预处理的另一种形式是对每个维度进行归一化，使得沿维度的最小值和最大值分别为-1 和 1。 如果您有理由相信不同的输入要素具有不同的比例（或单位），则应用此预处理才是有意义的，但他们应该与学习算法具有大致相同的重要性。在图像的情况下，像素的相对比例已经近似相等（并且在0-255范围之内），因此不必严格地执行该附加的预处理步骤</p>
</li>
<li><p>另一种类似于第一种的预处理方法是$PCA \space\space Whitening$ 。在此过程中，数据如上述所示先居中。然后，可以计算协方差矩阵，该矩阵高速我们数据中的相关结构：</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X -=np.mean(X, axis=<span class="number">0</span>)	<span class="comment"># zero-center</span></span><br><span class="line">cov = np.dot(X.T, X) / X.shape[<span class="number">0</span>]	<span class="comment"># compute the covariance matrix</span></span><br></pre></td></tr></table></figure>

<p>之后，通过将原始（但以零为中心）的数据投影到特征基础上来求解相关数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">U, S, V = np.linalg.svd(cov)	<span class="comment"># 计算数据协方差矩阵的SVD分解</span></span><br><span class="line">Xrot = np.dot(X, U)		<span class="comment"># 将数据分解</span></span><br></pre></td></tr></table></figure>

<p>最后一个转换是白化，它将特征基础中的数据取出来并将每个维度除以特征值以标准化比例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Xwhite = Xrot / np.sqrt(S + le<span class="number">-5</span>)	<span class="comment"># 除以特征值（他们是奇异值的平方根）</span></span><br></pre></td></tr></table></figure>

<p>注意，这里它增加一个<code>1e-5</code>（或一个小常数）以防止除零。这种转换的一个弱点是它可以极大地夸大数据中的噪声，因为它将所有维度（包括主要是噪声的微小方差的无关维度）拉伸到输入中的相同大小。实际上，这可以通过更强的平滑来减轻（即，将<code>1e-5</code>增加为更大的数量）</p>
<p>请注意，我们在此描述这些预处理只是为了完整性，实际上，这些变换不用于卷积神经网络。但是，将数据置零中心也非常重要，并且通常也会看到每个像素的归一化。</p>
<h3 id="3-网络的初始化"><a href="#3-网络的初始化" class="headerlink" title="3. 网络的初始化"></a>3. 网络的初始化</h3><p>现在，数据准备好了。但是，在开始训练网络之前，必须初始化其参数。</p>
<ul>
<li><p>全零初始化</p>
<p>在理想情况下，通过适当的数据归一化，我们可以合理的假设大约一半的权重是正的，而其中一半是负的。一个听起来合理的想法可能是将所有初始权重设置为零，但是，这证明是一个错误的想法。因为如果网络中的每个神经元计算相同的输出，那么他们也将在反向传播期间计算相同的梯度并经历完全相同的参数更新。换句话说，如果神经元的权重被初始化为相同，则神经元之间不存在不对称的来源</p>
</li>
<li><p>用小随机数初始化</p>
<p>因此，我们仍然希望权重非常接近零，但不是相同的零。通过这种方式，您可以将这些神经元随机变为非常接近零的小数，并将其视为对称性破坏。我们的想法是，神经元在开始时都是随机且独特的，因此他们将计算不同的更新并将自身整合为整个网络的不同部分。权重的实现可能看起来像$weight$ ~ $ 0.001 \times N(0, 1)$，$N(0, 1)$：零均值，单位标准差高斯。也可以使用从均匀分布中抽取的小叔子，但这似乎对实际中的最终性能的影响相对较小。</p>
</li>
<li><p>标准差异</p>
<p>上述建议的一个问题是来自随机初始化神经元的输出的分布具有随输入数量增长的方差。事实证明，您可以通过将其权重向量按其<em>扇入的</em>平方根（即其输入数）进行缩放，<strong>将每个神经元输出的方差归一化为1</strong>，如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w = np.random.randn(n) / sqrt(n) <span class="comment"># calibrating the variances with 1/sqrt(n)</span></span><br></pre></td></tr></table></figure>

<p>其中“randn”是前面提到的Gaussian，“n”是其输入的数量。这确保了网络中的所有神经元最初具有大致相同的输出分布并且凭经验提高了收敛速度。详细的推导可以从Page。幻灯片的18到23个。请注意，在推导中，它不考虑ReLU神经元的影响</p>
<p><strong>目前的建议：</strong></p>
<p>如前所述，通过校准神经元的方差进行的先前初始化不考虑ReLU。He <em>等人</em>最近关于这一主题的论文。<a href="http://arxiv.org/abs/1502.01852" target="_blank" rel="noopener">[4]</a>推导出一个专门针对ReLU的初始化，得出网络中神经元的方差应该如下的结论 $2.0 / n$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w = np.random.randn（n）* sqrt（<span class="number">2.0</span> / n）<span class="comment">#current recommendation</span></span><br></pre></td></tr></table></figure>

<p>这是目前在实践中使用的建议.</p>
</li>
</ul>
<h3 id="4-培训期间的一些提示"><a href="#4-培训期间的一些提示" class="headerlink" title="4. 培训期间的一些提示"></a>4. 培训期间的一些提示</h3><p>现在，一切都准备好了。让我们开始训练深层网络！</p>
<ul>
<li><p><strong>过滤器和池大小</strong>。在训练期间，输入图像的大小优选为2的幂，例如32（例如，<em>CIFAR-10</em>），<em>64,224</em>（例如，常用的<em>ImageNet</em>），384或512等。此外，它是重要的。使用具有零填充的小滤波器（例如$3 \times 3$）和小步幅（例如1），这不仅减少了参数的数量，而且提高了整个深度网络的准确率。同时，上面提到的特殊情况，即具有$3 \times 3$步幅1的滤波器，可以保持图像/特征图的空间大小。对于池化层，常用的池化大小为$2 \times 2$。</p>
</li>
<li><p><strong>学习率</strong>。此外，正如Ilya Sutskever <a href="http://yyue.blogspot.sg/2015/01/a-brief-overview-of-deep-learning.html/" target="_blank" rel="noopener">[2]</a>在博客中所描述的，他建议按小批量大小划分渐变。因此，如果更改迷你批量大小，则不应始终更改学习率（LR）。为了获得适当的LR，使用验证集是一种有效的方法。通常，训练开始时LR的典型值为0.1。在实践中，如果您发现您在验证集上停止了进展，则将LR除以2（或5），并继续前进，这可能会让您感到惊讶。</p>
</li>
<li><p><strong>在预先训练的模型上进行微调</strong>。如今，许多最先进的深层网络由着名研究团体发布，即<em>Caffe Model Zoo</em>和<em>VGG Group</em>。由于预训练深度模型具有出色的泛化能力，您可以直接将这些预先训练过的模型应用于您自己的应用程序。为了进一步提高数据集的分类性能，一种非常简单而有效的方法是根据您自己的数据微调预先训练的模型。如下表所示，两个最重要的因素是新数据集的大小（小或大），以及它与原始数据集的相似性。可以在不同情况下使用不同的微调策略。例如，一个很好的例子是您的新数据集与用于训练预训练模型的数据非常相似。在</p>
<table>
<thead>
<tr>
<th></th>
<th>Very similar dataset</th>
<th>very different dateset</th>
</tr>
</thead>
<tbody><tr>
<td><strong>very little data</strong></td>
<td>Use linear classifier on top layer</td>
<td>You’re in trouble……Try linear classifier from different stages</td>
</tr>
<tr>
<td><strong>quite a lot of data</strong></td>
<td>Finetune a few layers</td>
<td>Finetune a large number o flayers</td>
</tr>
</tbody></table>
<p>这种情况下，如果您的数据非常少，则可以在从预训练模型的顶层提取的特征上训练线性分类器。如果您手边有大量数据，请以较小的学习率微调一些预先训练过的模型。但是，如果您自己的数据集与预训练模型中使用的数据完全不同，但具有足够的训练图像，则应对您的数据进行微调，同时以较小的学习速率来提高性能。但是，如果您的数据集不仅包含很少的数据，而且与预先训练的模型中使用的数据非常不同，那么您将遇到麻烦。由于数据有限，仅训练线性分类器似乎更好。由于数据集非常不同，因此从网络顶部训练分类器可能不是最好的，因为网络包含更多数据集特定的功能。相反，在网络中较早的某个地方训练SVM分类器对激活/特征可能会更好。</p>
</li>
</ul>
<h3 id="5-激活功能的选择"><a href="#5-激活功能的选择" class="headerlink" title="5. 激活功能的选择"></a>5. 激活功能的选择</h3><p>深度网络的关键因素之一是<em>激活功能</em>，它将<strong>非线性</strong>带入网络。这里我们将介绍一些流行的激活函数的细节和特征，并在本节后面给出建议。</p>
<p><img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/imgs/neuron.png" alt="ç¥ç»å"></p>
<p>Sigmoid</p>
<p><img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/imgs/sigmod.png" alt="SIGMOD"></p>
<p>S形非线性具有数学形式<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/4713673387403833492-130.png" alt="西格玛（X）= 1 /（1 + E ^ { -  X}）">。它需要一个实数值，并将其“压缩”到0到1之间的范围内。特别是，大的负数变为0，大的正数变为1. S形函数在历史上经常被使用，因为它具有很好的解释作为神经元的射击速率：从完全不射击（0）到假定最大频率（1）的完全饱和射击。</p>
<p>在实践中，S形非线性最近已失宠，很少使用。它有两个主要缺点：</p>
<ul>
<li><p>Sigmoids饱和并杀死渐变。乙状结肠神经元的一个非常不希望的特性是，当神经元的激活在0或1的尾部饱和时，这些区域的梯度几乎为零。回想一下，在反向传播期间，这个（局部）梯度将乘以该门的输出的梯度以用于整个目标。因此，如果局部梯度非常小，它将有效地“杀死”梯度，并且几乎没有信号将通过神经元流到其权重并递归地流向其数据。此外，在初始化乙状结肠神经元的重量以防止饱和时，必须格外小心。例如，如果初始权重太大，那么大多数神经元将变得饱和，网络几乎不会学习。</p>
</li>
<li><p>Sigmoid输出不是以零为中心的*。这是不合需要的，因为神经网络中后续处理层中的神经元（很快就会更多）将接收非零中心的数据。这对梯度下降期间的动态有影响，因为如果进入神经元的数据总是正的（例如，<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/5999452984634080335-130.png" alt="X&gt; 0">元素方式<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/2668512978356043857-130.png" alt="F =瓦特^的Tx + B">），那么<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/15232045814-130.png" alt="w ^">在反向传播期间权重的梯度将变为全部为正，或者全部为负（取决于整个表达的梯度<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/13056039271-130.png" alt="F">）。这可能会在权重的梯度更新中引入不希望的锯齿形动态。但是，请注意，一旦这些渐变在一批数据中相加，权重的最终更新可能会有可变符号，从某种程度上缓解了这个问题。因此，这是不方便的，但与上述饱和激活问题相比，其具有较不严重的后果。</p>
</li>
</ul>
<h4 id="tanh（x）"><a href="#tanh（x）" class="headerlink" title="tanh（x）"></a>tanh（x）</h4><p><img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/imgs/tanh.png" alt="æ­£å"></p>
<p>tanh非线性将实数值压缩到范围[-1,1]。像S形神经元一样，它的激活饱和，但与S形神经元不同，它的输出是零中心的。因此，在实践中，tanh非线性总是优于S形非线性。</p>
<h4 id="Rectified-Linear-Unit（整流线性单元）"><a href="#Rectified-Linear-Unit（整流线性单元）" class="headerlink" title="Rectified Linear Unit（整流线性单元）"></a>Rectified Linear Unit（整流线性单元）</h4><p>整流线性单元（ReLU）在过去几年中变得非常流行。它计算函数<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/3442307160410329206-130.png" alt="F（X）= MAX（0，x）的">，它简单地设置为零阈值</p>
<ul>
<li><p>（<em>优点</em>）与涉及昂贵操作（指数等）的sigmoid / tanh神经元相比，可以通过简单地将激活矩阵设置为零来实现ReLU。同时，ReLUs不会饱和。</p>
</li>
<li><p>（<em>优点</em>）发现与sigmoid / tanh函数相比，随机梯度下降的收敛大大加速（例如，<a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">[1]中</a>的因子为6 ）。有人认为这是由于它的线性，非饱和形式。</p>
</li>
<li><p>（<em>缺点</em>）不幸的是，ReLU单位在训练期间可能很脆弱并且可能“死亡”。例如，流过ReLU神经元的大梯度可能导致权重更新，使得神经元永远不会再次激活任何数据点。如果发生这种情况，那么流经该单元的梯度将从该点开始永远为零。也就是说，ReLU单元可以在训练期间不可逆转地死亡，因为它们可以从数据流形中被淘汰。例如，如果学习率设置得太高，您可能会发现多达40％的网络可能“死”（即，永远不会在整个训练数据集中激活的神经元）。通过适当设置学习率，这不是一个问题。</p>
</li>
</ul>
<h4 id="Leaky-ReLU"><a href="#Leaky-ReLU" class="headerlink" title="Leaky ReLU"></a>Leaky ReLU</h4><p><img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/imgs/leaky.png" alt="lrelu"></p>
<p>Leaky ReLUs是解决“垂死的ReLU”问题的一次尝试。当<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/5999452984636080433-130.png" alt="x &lt;0的">泄漏的ReLU反而具有小的负斜率（0.01或左右）时，而不是函数为零。也就是说，该函数计算<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/4196616167090173439-130.png" alt="f（x）= alpha x">if <img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/5999452984636080433-130.png" alt="x &lt;0的">和<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/5484684767813338902-130.png" alt="F（X）= X">if <img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/4437941819613442466-130.png" alt="xgeq 0">，where <img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/7227645438722938594-130.png" alt="α">是一个小常量。有些人用这种形式的激活函数报告成功，但结果并不总是一致的</p>
<h4 id="Parametric-ReLU-参数化ReLU"><a href="#Parametric-ReLU-参数化ReLU" class="headerlink" title="Parametric ReLU(参数化ReLU)"></a>Parametric ReLU(参数化ReLU)</h4><p>如今，提出了更广泛的激活功能，即<strong>整流单元族</strong>。在下文中，我们将讨论ReLU的变体。</p>
<p><img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/imgs/relufamily.png" alt="relufamily"></p>
<p>ReLU，Leaky ReLU，PReLU和RReLU。在这些图中，对于PReLU，<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/2031553203773749404-130.png" alt="alpha_i">是学习而Leaky ReLU <img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/2031553203773749404-130.png" alt="alpha_i">是固定的。对于RReLU，<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/8090385205122200253-130.png" alt="alpha_ {}纪">随机变量是在给定范围内保持采样，并在测试中保持固定。</p>
<p>第一种变体称为<em>参数整流线性单元</em>（<em>PReLU</em>）<a href="http://arxiv.org/abs/1502.01852" target="_blank" rel="noopener">[4]</a>。在PReLU中，负面部分的斜率是从数据而不是预定义中学习的。他<em>等人</em>。<a href="http://arxiv.org/abs/1502.01852" target="_blank" rel="noopener">[4]</a>声称PReLU是超越<a href="http://www.image-net.org/" target="_blank" rel="noopener">ImageNet</a>分类任务的人类表现的关键因素。PReLU的反向传播和更新过程非常简单，类似于传统的ReLU</p>
<h4 id="随机ReLU"><a href="#随机ReLU" class="headerlink" title="随机ReLU"></a>随机ReLU</h4><p>第二种变体称为<em>随机整流线性单元</em>（<em>RReLU</em>）。在RReLU中，负部分的斜率在训练中的给定范围内随机化，然后在测试中固定。如<a href="http://arxiv.org/abs/1505.00853" target="_blank" rel="noopener">[5]中所述</a>，在最近的Kaggle <a href="https://www.kaggle.com/c/datasciencebowl" target="_blank" rel="noopener">国家数据科学碗（NDSB）</a>竞赛中，据报道RReLU由于其随机性质可以减少过度拟合。此外，由NDSB比赛获胜者建议<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/2031553203773749404-130.png" alt="alpha_i">，训练中的随机抽样从<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/348464217043394429-130.png" alt="1 / U（3,8）">测试时间开始，并且在测试时间内被固定为其期望，即<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/6504549066650438132-130.png" alt="2 /（1 + U）= 2/11">。</p>
<p>在<a href="http://arxiv.org/abs/1505.00853" target="_blank" rel="noopener">[5]中</a>，作者评估了<em>CIFAR-10</em>，<em>CIFAR-100</em>和<em>NDSB</em>数据集上具有不同激活函数的两种最先进CNN架构的分类性能，如下表所示。<em>请注意，对于这两个网络，激活功能后面是每个卷积层。而<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/12416037344-130.png" alt="一个">这些表中的实际表明<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/6763807723309486172-130.png" alt="1 /α-">，<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/7227645438722938594-130.png" alt="α">上述斜率在哪里</em>。</p>
<p><img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/imgs/relures.png" alt="relures"></p>
<p>从这些表中，我们可以发现ReLU的性能并不是所有三个数据集的最佳性能。对于Leaky ReLU，更大的斜率<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/7227645438722938594-130.png" alt="α">将获得更好的准确率。PReLU很容易在小数据集上过度拟合（其训练误差最小，而测试误差不尽如人意），但仍然优于ReLU。此外，RReLU明显优于NDSB上的其他激活功能，这表明RReLU可以克服过度拟合，因为该数据集的训练数据少于CIFAR-10 / CIFAR-100。<strong>总之，在这三个数据集中，三种类型的ReLU变体都始终优于原始ReLU。而PReLU和RReLU似乎是更好的选择。此外，何等人。[4]**</strong>也报道了类似的结论**。</p>
<h3 id="6-多样化的正规化"><a href="#6-多样化的正规化" class="headerlink" title="6. 多样化的正规化"></a>6. 多样化的正规化</h3><p>有几种方法可以控制神经网络的容量以防止过度拟合：</p>
<ul>
<li><strong>L2 regularization（L2正则化）</strong>可能是最常见的正则化形式。它可以通过直接在目标中惩罚所有参数的平方幅度来实现。也就是说，对于<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/15232045814-130.png" alt="w ^">网络中的每个权重，我们将该项添加<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/4439456383146610173-130.png" alt="frac {1} {2} lambda w ^ 2">到目标中，其中<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/9213219682577124982-130.png" alt="拉姆达">是正则化强度。通常会看到<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/7924204476109182584-130.png" alt="压裂{1} {2}">前面的因素，因为这个术语相对于参数的梯度<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/15232045814-130.png" alt="w ^">只是简单<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/2768874965512882837-130.png" alt="拉姆达威">而不是<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/2017924880831122006-130.png" alt="2 lambda w">。L2正则化具有严重惩罚峰值权重向量并且优选漫反射权向量的直观解释。</li>
<li><strong>L1 regularizationL1（正则化）</strong>是另一种相对常见的正则化形式，其中对于每个权重，<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/15232045814-130.png" alt="w ^">我们将该术语添加<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/1540651743016124243-130.png" alt="lambda | w |">到目标中。可以将L1正则化与L2正则化相结合:( <img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/5909288400939027289-130.png" alt="lambda_1 | w | + lambda_2 w ^ 2">这称为[弹性网正则化](<a href="http://web.stanford.edu/~hastie/Papers/B67.2" target="_blank" rel="noopener">http://web.stanford.edu/~hastie/Papers/B67.2</a> (2005) 301-320 Zou &amp; Hastie.pdf)）。L1正则化具有引人注目的特性，即它导致权重向量在优化期间变得稀疏（即非常接近于零）。换句话说，具有L1正则化的神经元最终仅使用其最重要输入的稀疏子集并且变得几乎不变于“噪声”输入。相比之下，来自L2正则化的最终权重向量通常是漫反射的，小数目。实际上，如果您不关心明确的特征选择，可以期望L2正则化比L1具有更好的性能。</li>
<li><strong>Max norm constraints（最大范数约束）</strong>。另一种形式的正则化是对每个神经元的权重向量的大小强制执行绝对上限，并使用预计的梯度下降来强制执行约束。实际上，这对应于正常执行参数更新，然后通过钳制<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/6235765355760146286-130.png" alt="VEC【W】">每个神经元的权重向量来实现约束以满足<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/5858718376305099-130.png" alt="并行vec {w} parallel_2 &lt;c">。典型值为<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/12672038114-130.png" alt="C">3或4的订单。有些人报告使用这种正规化形式时的改进。其吸引人的特性之一是，即使学习率设置得太高，网络也无法“爆炸”，因为更新总是有限的。</li>
<li><strong>Dropout</strong>是Srivastava <em>等人</em>非常有效，简单且最近引入的正则化技术。在<a href="http://jmlr.org/papers/v15/srivastava14a.html" target="_blank" rel="noopener">[6]</a>中补充了其他方法（L1，L2，maxnorm）。在训练期间，丢失可以解释为在完整神经网络内对神经网络进行采样，并且仅基于输入数据更新采样网络的参数。（然而，可能的采样网络的指数数量并不是独立的，因为它们共享参数。）在测试期间，没有应用丢失，并且解释了评估所有子网络的指数级整体的平均预测（更多关于合奏在下一节）。在实践中，辍学率的价值<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/7993929496961263-130.png" alt="P = 0.5"> 是一个合理的默认值，但可以根据验证数据进行调整。</li>
</ul>
<p><img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/imgs/dropout.png" alt="éåº"></p>
<p>最常用的正则化技术<em>dropout</em> <a href="http://jmlr.org/papers/v15/srivastava14a.html" target="_blank" rel="noopener">[6]</a>。在训练时，通过仅以一定概率保持神经元活动<img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/eqs/14336043121-130.png" alt="p">（超参数）或者将其设置为零来实现丢失。</p>
<h3 id="7-从数字中找到的一些见解"><a href="#7-从数字中找到的一些见解" class="headerlink" title="7. 从数字中找到的一些见解"></a>7. 从数字中找到的一些见解</h3><p>最后，根据上面的提示，您可以为自己的深层网络获得满意的设置（例如，数据处理，架构选择和详细信息等）。在培训期间，您可以绘制一些数字来表明您的网络的培训效果。</p>
<ul>
<li>众所周知，学习率非常敏感。从下面的图1可以看出，非常高的学习率将导致一个非常奇怪的损失曲线。即使在大量时期之后，低学习率也会使您的训练损失减慢得非常缓慢。相反，高学习率会使训练损失在开始时快速下降，但也会降低到局部最小值。因此，在这种情况下，您的网络可能无法取得令人满意的结果。为了获得良好的学习率，如图1所示的红线，其损耗曲线表现平稳，最终达到最佳性能。</li>
<li>现在让我们放大损失曲线。时期表示在训练数据上训练一次的次数，因此每个时期有多个小批量。如果我们在每个训练批次中绘制分类损失，则曲线如图2所示。与图1类似，如果损失曲线的趋势看起来过于线性，则表明您的学习率较低; 如果它没有减少太多，它会告诉你学习率可能太高了。而且，曲线的“宽度”与批量大小有关。如果“宽度”看起来太宽，也就是说每个批次之间的差异太大，这表明您应该增加批量大小。</li>
<li>另一个提示来自准确度曲线。如图3所示，红线是训练精度，绿线是验证线。当验证准确度收敛时，红线和绿线之间的差距将显示深层网络的有效性。如果差距很大，则表明您的网络可以在训练数据上获得良好的准确性，而在验证集上只能达到较低的准确度。很明显，你的深层模型会过度训练。因此，您应该增加深度网络的正则化强度。然而，同时在低精度水平上没有差距并不是一件好事，这表明你的深层模型具有较低的可学习性。在这种情况下，最好增加模型容量以获得更好的结果。</li>
</ul>
<p><img src="http://lamda.nju.edu.cn/weixs/project/CNNTricks/imgs/trainfigs.png" alt="trainfigs"></p>
<h3 id="8-集合多个深度网络的办法"><a href="#8-集合多个深度网络的办法" class="headerlink" title="8. 集合多个深度网络的办法"></a>8. 集合多个深度网络的办法</h3><p>在机器学习中，训练多个学习者然后将它们组合起来使用的集合方法<a href="https://www.crcpress.com/Ensemble-Methods-Foundations-and-Algorithms/Zhou/9781439830031" target="_blank" rel="noopener">[8]</a>是一种最先进的学习方法。众所周知，集合通常比单个学习者更准确，并且集合方法已经在许多现实世界的任务中取得了巨大的成功。在实际应用中，特别是挑战或比赛中，几乎所有的第一名和第二名的获胜者都使用了整体方法。</p>
<p>在这里，我们介绍了深度学习场景中的集合的几种技能。</p>
<ul>
<li><strong>相同型号，不同的初始化</strong>。使用交叉验证来确定最佳超参数，然后使用最佳超参数集训练多个模型，但使用不同的随机初始化。这种方法的危险在于变化只是由于初始化。</li>
<li><strong>在交叉验证期间发现的顶级模型</strong>。使用交叉验证来确定最佳超参数，然后选择前几个（例如10个）模型来形成整体。这改善了整体的多样性，但存在包括次优模型的危险。在实践中，这可以更容易执行，因为在交叉验证之后不需要额外的模型再训练。实际上，您可以直接从<a href="https://github.com/BVLC/caffe/wiki/Model-Zoo" target="_blank" rel="noopener">Caffe Model Zoo中</a>选择几个最先进的深度模型来执行整体。</li>
<li><strong>单个模型的不同检查点</strong>。如果培训非常昂贵，那么有些人在一段时间内（例如在每个时期之后）采用单个网络的不同检查点并使用这些检查点形成整体的成功有限。显然，这种情况有些缺乏，但在实践中仍然可以很好地运作。这种方法的优点是非常便宜。</li>
<li><strong>一些实际的例子</strong>。如果您的视觉任务与高级图像语义相关，例如，来自静止图像的事件识别，则更好的集合方法是使用在不同数据源上训练的多个深度模型来提取不同的和互补的深度表示。例如，在与<a href="http://pamitc.org/iccv15/" target="_blank" rel="noopener">ICCV’15</a>相关的<a href="https://www.codalab.org/competitions/4081#learn_the_details" target="_blank" rel="noopener">文化事件识别</a>挑战中，我们使用了五种不同的深度模型，这些模型训练了<a href="http://www.image-net.org/" target="_blank" rel="noopener">ImageNet</a>，<a href="http://places.csail.mit.edu/" target="_blank" rel="noopener">地方数据库</a>和<a href="http://gesture.chalearn.org/" target="_blank" rel="noopener">竞赛组织者</a>提供的文化图像。之后，我们提取了五个互补的深层特征，并将它们视为多视图数据。结合<a href="http://lamda.nju.edu.cn/weixs/publication/iccvw15_CER.pdf" target="_blank" rel="noopener">[7]中</a>描述的“早期融合”和“晚期融合”策略，我们取得了最佳表现之一，并在该挑战中排名第二。与我们的工作类似，<a href="http://cs231n.stanford.edu/reports/milad_final_report.pdf" target="_blank" rel="noopener">[9]</a>提出了<em>Stacked NN</em>框架，以同时融合更深层次的网络。</li>
</ul>
<h4 id="杂："><a href="#杂：" class="headerlink" title="杂："></a>杂：</h4><p>在实际应用中，数据通常是<strong>类不平衡的</strong>：一些类具有大量图像/训练实例，而一些类具有非常有限数量的图像。正如最近的技术报告<a href="http://www.diva-portal.org/smash/get/diva2:811111/FULLTEXT01.pdf" target="_blank" rel="noopener">[10]中</a>所讨论的，当深度CNN在这些不平衡训练集上进行训练时，结果表明不平衡训练数据可能对深度网络中的整体性能产生严重的负面影响。对于这个问题，最简单的方法是通过直接对不平衡数据进行上采样和下采样来平衡训练数据，如<a href="http://www.diva-portal.org/smash/get/diva2:811111/FULLTEXT01.pdf" target="_blank" rel="noopener">[10]</a>所示。另一个有趣的解决方案是我们的挑战解决方案中的一种特殊作物加工<a href="http://lamda.nju.edu.cn/weixs/publication/iccvw15_CER.pdf" target="_blank" rel="noopener">[7]</a>。由于原始文化事件图像不平衡，我们只从具有少量训练图像的类中提取作物，一方面可以提供不同的数据源，另一方面可以解决类不平衡问题。此外，您可以调整微调策略以克服阶级不平衡。例如，您可以将自己的数据集分为两部分：一部分包含具有大量训练样本（图像/作物）的类; 另一个包含有限数量的样本类。在每个部分，阶级不平衡的问题都不会很严重。在对数据集进行微调开始时，首先要对具有大量训练样本（图像/作物）的类进行微调，其次，继续微调，但是对有限数量的样本进行微调</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/6/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><a class="extend next" rel="next" href="/page/8/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Mariana</p>
              <p class="site-description motion-element" itemprop="description">a study blog</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">102</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Mariana</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
