<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <link rel="alternate" href="/atom.xml" title="Celery Fairy" type="application/atom+xml">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://woojoo520.github.io').hostname,
    root: '/',
    scheme: 'Pisces',
    version: '7.5.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="损失函数  平方误差损失 每个训练样本的平方误差损失（也称为L2 Loss）是实际值和预测值之差的平方  相应的成本函数是这些平方误差的平均值（MSE），它是一个二次函数（形式为ax^2+bx+c），并且值大于等于0,。二次函数具有全局最小值，由于没有局部最小值，所以永远不会陷入它。因此，可以保证梯度下降将收敛到全局最小值（如果完全收敛的话） MSE损失函数通过使用平方误差来惩罚模型，有一个缺点">
<meta property="og:type" content="article">
<meta property="og:title" content="损失函数">
<meta property="og:url" content="https://woojoo520.github.io/2019/11/24/损失函数/index.html">
<meta property="og:site_name" content="Celery Fairy">
<meta property="og:description" content="损失函数  平方误差损失 每个训练样本的平方误差损失（也称为L2 Loss）是实际值和预测值之差的平方  相应的成本函数是这些平方误差的平均值（MSE），它是一个二次函数（形式为ax^2+bx+c），并且值大于等于0,。二次函数具有全局最小值，由于没有局部最小值，所以永远不会陷入它。因此，可以保证梯度下降将收敛到全局最小值（如果完全收敛的话） MSE损失函数通过使用平方误差来惩罚模型，有一个缺点">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://pic2.zhimg.com/v2-776284ef8ef1892adca72454c80723dd_b.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/v2-77f5689dd45999c25bb55a1008e2cdf1_b.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/v2-333ad2d90605b5d0de9ee4ec509ee49d_b.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/v2-dd86aad2ba3885b36dfc9db902baadc3_b.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/v2-47ddb7df995d3978f53bd2b877e4c25d_b.jpg">
<meta property="og:image" content="https://pic1.zhimg.com/v2-d6a0a7f3bb804cd5c0dcaa2f1b908ee8_b.jpg">
<meta property="og:image" content="https://pic1.zhimg.com/v2-95dba4bbda5ed968482df244137cbcf4_b.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/v2-739534b9c71db800ca910f72a3152e13_b.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/v2-c465dd0ad165c0e3501d7d6608188c41_b.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/v2-953d3605358f94ee5833084e75705756_b.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/v2-be2d1fea2669befa924891c3bd7c8e12_b.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/v2-e78029297910deac90414234151aca9e_b.jpg">
<meta property="og:updated_time" content="2019-11-24T14:01:24.685Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="损失函数">
<meta name="twitter:description" content="损失函数  平方误差损失 每个训练样本的平方误差损失（也称为L2 Loss）是实际值和预测值之差的平方  相应的成本函数是这些平方误差的平均值（MSE），它是一个二次函数（形式为ax^2+bx+c），并且值大于等于0,。二次函数具有全局最小值，由于没有局部最小值，所以永远不会陷入它。因此，可以保证梯度下降将收敛到全局最小值（如果完全收敛的话） MSE损失函数通过使用平方误差来惩罚模型，有一个缺点">
<meta name="twitter:image" content="https://pic2.zhimg.com/v2-776284ef8ef1892adca72454c80723dd_b.jpg">

<link rel="canonical" href="https://woojoo520.github.io/2019/11/24/损失函数/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>损失函数 | Celery Fairy</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Celery Fairy</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Celery's Blog</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://woojoo520.github.io/2019/11/24/损失函数/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo.gif">
      <meta itemprop="name" content="Woojoo">
      <meta itemprop="description" content="a study blog">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Celery Fairy">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          损失函数
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2019-11-24 13:36:54 / 修改时间：22:01:24" itemprop="dateCreated datePublished" datetime="2019-11-24T13:36:54+08:00">2019-11-24</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2019/11/24/损失函数/#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2019/11/24/损失函数/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="损失函数"><a class="markdownIt-Anchor" href="#损失函数"></a> 损失函数</h2>
<h3 id="平方误差损失"><a class="markdownIt-Anchor" href="#平方误差损失"></a> 平方误差损失</h3>
<p>每个训练样本的平方误差损失（也称为L2 Loss）是实际值和预测值之差的平方</p>
<p><img src="https://pic2.zhimg.com/v2-776284ef8ef1892adca72454c80723dd_b.jpg" alt="img"></p>
<p>相应的成本函数是这些平方误差的平均值（MSE），它是一个二次函数（形式为ax^2+bx+c），并且值大于等于0,。二次函数具有全局最小值，由于没有局部最小值，所以永远不会陷入它。因此，可以保证梯度下降将收敛到全局最小值（如果完全收敛的话）</p>
<p>MSE损失函数通过使用平方误差来惩罚模型，有一个缺点，把一个比较大的数的平方会使它变得更大。但有一点需要注意，这个属性使<strong>MSE成本函数对异常值的健壮性降低。因此，如果我们的数据容易出现许多的异常值，则不应该使用它</strong></p>
<h3 id="绝对误差损失"><a class="markdownIt-Anchor" href="#绝对误差损失"></a> 绝对误差损失</h3>
<p>每个训练样本的绝对误差是预测值和实际值之间的距离，与符号无关。绝对误差也称为L1 Loss</p>
<p><img src="https://pic2.zhimg.com/v2-77f5689dd45999c25bb55a1008e2cdf1_b.jpg" alt="img"></p>
<p>成本是这些绝对误差的平均值（MAE）。与MSE相比，<strong>MAE成本对异常值更加健壮</strong>。但是，<strong>在数学方程中处理绝对或模数运算符并不容易</strong>。</p>
<h3 id="huber损失"><a class="markdownIt-Anchor" href="#huber损失"></a> Huber损失</h3>
<p>结合了MSE和MAE的最佳特性。对于较小的误差，他是二次的，否则是线性的（对于其梯度也是如此）。Huber损失需要确定<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03785em;">δ</span></span></span></span>参数</p>
<p><img src="https://pic2.zhimg.com/v2-333ad2d90605b5d0de9ee4ec509ee49d_b.jpg" alt="img"></p>
<p>Huber损失对于异常值比MSE更强。<strong>它用于稳健回归，M估计法（M-estimator）和可加模型（additive model）。Huber损失的变体也可用于分类。</strong></p>
<h3 id="二分类损失函数"><a class="markdownIt-Anchor" href="#二分类损失函数"></a> 二分类损失函数</h3>
<p>给分类基于应用于输入特征向量的规则则</p>
<h4 id="二元交叉熵损失"><a class="markdownIt-Anchor" href="#二元交叉熵损失"></a> 二元交叉熵损失</h4>
<p>熵是用来表示无序性和不确定性。测量具有芥蓝菜分布<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span>的随机变量X</p>
<p><img src="https://pic4.zhimg.com/v2-dd86aad2ba3885b36dfc9db902baadc3_b.jpg" alt="img"></p>
<p>负号使用于最后结果为正数</p>
<blockquote>
<p>概率分布的熵值越大，表明分布的不确定性越大。同样，一个较小的值代表一个更确定的分布</p>
</blockquote>
<p>这使得二元交叉熵适合作为损失函数（你希望最小化其值）。我们对输出概率p的分类模型使用二元交叉熵损失</p>
<blockquote>
<p>元素属于第1类（或正类）的概率=p</p>
<p>元素属于第0类（或负类）的概率=1-p</p>
</blockquote>
<p>然后，输出标签y（可以取值0和1）的交叉熵损失和预测概率p定义为：</p>
<p><img src="https://pic2.zhimg.com/v2-47ddb7df995d3978f53bd2b877e4c25d_b.jpg" alt="img"></p>
<p>这也称为Log-Loss（对数损失）。为了计算概率p，可以使用sigmoid函数。其中，z是输入功能的函数</p>
<p><img src="https://pic1.zhimg.com/v2-d6a0a7f3bb804cd5c0dcaa2f1b908ee8_b.jpg" alt="img"></p>
<p>sigmoid函数的范围是[0, 1]这使得它适合于计算概率</p>
<p><img src="https://pic1.zhimg.com/v2-95dba4bbda5ed968482df244137cbcf4_b.jpg" alt="img"></p>
<h4 id="hinge损失"><a class="markdownIt-Anchor" href="#hinge损失"></a> Hinge损失</h4>
<p><strong>Hinge损失主要用于带有类标签-1和1的支持向量机（SVM）</strong>。因此，请确保将数据集中“恶性”类标签从0更改为-1</p>
<blockquote>
<p>Hinge损失不仅会惩罚错误的预测，还会惩罚不自信的正确预测</p>
</blockquote>
<p>数据对<code>(x, y)</code>的Hinge损失如图：</p>
<p><img src="https://pic4.zhimg.com/v2-739534b9c71db800ca910f72a3152e13_b.jpg" alt="img"></p>
<p>Hinge损失简化了SVM的数学运算，同时最大化了损失（与对数损失（Log-Loss）相比）。当我们想要做实时决策而不是高度关注准确性时，就可以使用它</p>
<h3 id="多分类损失函数"><a class="markdownIt-Anchor" href="#多分类损失函数"></a> 多分类损失函数</h3>
<h4 id="多分类交叉熵"><a class="markdownIt-Anchor" href="#多分类交叉熵"></a> 多分类交叉熵</h4>
<p>多分类交叉熵损失是二元交叉熵损失的退矿。输入向量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>X</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">X_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和相应的ont-hot编码目标向量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>Y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">Y_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的损失是：</p>
<p><img src="https://pic2.zhimg.com/v2-c465dd0ad165c0e3501d7d6608188c41_b.jpg" alt="img"></p>
<p>使用softmax函数来找到概率<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>P</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">P_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span></p>
<p><img src="https://pic3.zhimg.com/v2-953d3605358f94ee5833084e75705756_b.jpg" alt="img"></p>
<p>softmax层是接在神经网络的输出层前。Softmax层必须与输出层具有相同数量的节点</p>
<p><img src="https://pic3.zhimg.com/v2-be2d1fea2669befa924891c3bd7c8e12_b.jpg" alt="img"></p>
<p>最后，我们的输出是具有给定输入的最大概率的类别</p>
<h4 id="kl散度"><a class="markdownIt-Anchor" href="#kl散度"></a> KL散度</h4>
<p>KL散度是概率分布与另一个概率分布区别的度量。KL散度为零表示分布相同</p>
<p><img src="https://pic3.zhimg.com/v2-e78029297910deac90414234151aca9e_b.jpg" alt="img"></p>
<p>注意，发散函数不对称</p>
<p>与多分类分类相比，KL散度更常用于逼近复杂函数。我们在使用变分自动编码器（VAE）等深度生成模型时经常使用KL散度</p>
<h3 id="pytorch实战"><a class="markdownIt-Anchor" href="#pytorch实战"></a> Pytorch实战</h3>
<p>损失函数的基本用法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">criterion = LossCriterion()	# 构造函数有自己的参数</span><br><span class="line">loss = criterion(x, y)		# 调用标准时也有参数</span><br></pre></td></tr></table></figure>
<p>得到的loss结果已经对mini-batch数量取了平均值</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2019/11/24/DANN/" rel="prev" title="DANN">
      <i class="fa fa-chevron-left"></i> DANN
    </a></div>
      <div class="post-nav-item">
    <a href="/2019/11/25/PCA原理详解/" rel="next" title="PCA原理详解">
      PCA原理详解 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="comments"></div>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#损失函数"><span class="nav-number">1.</span> <span class="nav-text"> 损失函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#平方误差损失"><span class="nav-number">1.1.</span> <span class="nav-text"> 平方误差损失</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#绝对误差损失"><span class="nav-number">1.2.</span> <span class="nav-text"> 绝对误差损失</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#huber损失"><span class="nav-number">1.3.</span> <span class="nav-text"> Huber损失</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#二分类损失函数"><span class="nav-number">1.4.</span> <span class="nav-text"> 二分类损失函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#二元交叉熵损失"><span class="nav-number">1.4.1.</span> <span class="nav-text"> 二元交叉熵损失</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#hinge损失"><span class="nav-number">1.4.2.</span> <span class="nav-text"> Hinge损失</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#多分类损失函数"><span class="nav-number">1.5.</span> <span class="nav-text"> 多分类损失函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#多分类交叉熵"><span class="nav-number">1.5.1.</span> <span class="nav-text"> 多分类交叉熵</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#kl散度"><span class="nav-number">1.5.2.</span> <span class="nav-text"> KL散度</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#pytorch实战"><span class="nav-number">1.6.</span> <span class="nav-text"> Pytorch实战</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Woojoo"
      src="/images/logo.gif">
  <p class="site-author-name" itemprop="name">Woojoo</p>
  <div class="site-description" itemprop="description">a study blog</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">133</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Woojoo</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://pisces.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.5.0
  </div>

        








        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  
















  

  

  


<script>
NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(item => {
    return GUEST.includes(item);
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'aKRj8pzPJm0LdONJb0Ci0U5L-gzGzoHsz',
    appKey: 'vA8nbcq2HgWrqovGq6LwXRG1',
    placeholder: "Just go go",
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false,
    lang: '' || 'zh-cn',
    path: location.pathname,
    recordIP: false,
    serverURLs: ''
  });
}, window.Valine);
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
