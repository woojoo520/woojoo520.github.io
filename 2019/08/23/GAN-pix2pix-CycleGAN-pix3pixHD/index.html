<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>GAN-pix2pix-CycleGAN-pix3pixHD | Celery Fairy</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="GAN解决的问题： $\min _{G} \max _{D} \mathbb{E}[\log D(G(z))+\log (1-D(x))]$ 传统的GAN的不足：  没有用户控制能力 在传统的GAN里，输入一个随机噪声，就回输出一幅随机图像 但是，用户想输出的图像是和输入有对应的、有关联的。比如输入一只猫的草图，输出同一形态的猫的真实图片（这里对形态的要求就是一种用户控制）   低分辨率（Low">
<meta property="og:type" content="article">
<meta property="og:title" content="GAN-pix2pix-CycleGAN-pix3pixHD">
<meta property="og:url" content="https://woojoo520.github.io/2019/08/23/GAN-pix2pix-CycleGAN-pix3pixHD/index.html">
<meta property="og:site_name" content="Celery Fairy">
<meta property="og:description" content="GAN解决的问题： $\min _{G} \max _{D} \mathbb{E}[\log D(G(z))+\log (1-D(x))]$ 传统的GAN的不足：  没有用户控制能力 在传统的GAN里，输入一个随机噪声，就回输出一幅随机图像 但是，用户想输出的图像是和输入有对应的、有关联的。比如输入一只猫的草图，输出同一形态的猫的真实图片（这里对形态的要求就是一种用户控制）   低分辨率（Low">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://img-blog.csdn.net/20180914044453345?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dkeW1pbmQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:image" content="https://img-blog.csdn.net/20180914044507384?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dkeW1pbmQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:image" content="https://img-blog.csdn.net/20180914044518280?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dkeW1pbmQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:image" content="https://img-blog.csdn.net/20180914044620941?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dkeW1pbmQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:image" content="https://img-blog.csdn.net/20180914044822913?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dkeW1pbmQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:image" content="https://img-blog.csdn.net/20180914044837669?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dkeW1pbmQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:image" content="https://img-blog.csdn.net/20180914044908950?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dkeW1pbmQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:image" content="https://img-blog.csdn.net/20180914044947503?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dkeW1pbmQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:image" content="https://img-blog.csdn.net/20180914045410513?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dkeW1pbmQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:updated_time" content="2019-08-23T04:33:47.276Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="GAN-pix2pix-CycleGAN-pix3pixHD">
<meta name="twitter:description" content="GAN解决的问题： $\min _{G} \max _{D} \mathbb{E}[\log D(G(z))+\log (1-D(x))]$ 传统的GAN的不足：  没有用户控制能力 在传统的GAN里，输入一个随机噪声，就回输出一幅随机图像 但是，用户想输出的图像是和输入有对应的、有关联的。比如输入一只猫的草图，输出同一形态的猫的真实图片（这里对形态的要求就是一种用户控制）   低分辨率（Low">
<meta name="twitter:image" content="https://img-blog.csdn.net/20180914044453345?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dkeW1pbmQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
  
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Celery Fairy</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
      </nav>
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://woojoo520.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-GAN-pix2pix-CycleGAN-pix3pixHD" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/08/23/GAN-pix2pix-CycleGAN-pix3pixHD/" class="article-date">
  <time datetime="2019-08-23T03:04:42.000Z" itemprop="datePublished">2019-08-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      GAN-pix2pix-CycleGAN-pix3pixHD
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h3><p>解决的问题：</p>
<p>$\min _{G} \max _{D} \mathbb{E}[\log D(G(z))+\log (1-D(x))]$</p>
<p>传统的GAN的不足：</p>
<ul>
<li><p>没有<strong>用户控制</strong>能力</p>
<p>在传统的GAN里，输入一个随机噪声，就回输出一幅随机图像</p>
<p>但是，用户想输出的图像是和输入<strong>有对应的、有关联的</strong>。比如输入一只猫的草图，输出同一形态的猫的真实图片（这里对形态的要求就是一种用户控制）</p>
<p><img src="https://img-blog.csdn.net/20180914044453345?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dkeW1pbmQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="è¿éåå¾çæè¿°"></p>
</li>
<li><p>低分辨率（Low resolution）和低质量（Low quality）问题</p>
<p>尽管生成的图片看起来很不错，但是如果放大看，就会发现细节相当模糊</p>
<p><img src="https://img-blog.csdn.net/20180914044507384?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dkeW1pbmQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="è¿éåå¾çæè¿°"></p>
</li>
</ul>
<p>改善的目的就是（1）提高GAN的用户控制能力（2）提高GAN生成图片的分辨率和质量</p>
<p><strong>步骤：</strong></p>
<p><strong>pix2pix</strong>：有条件地使用用户输入，它使用<strong>成对的数据</strong>进行训练</p>
<p><strong>CycleGAN：</strong>使用<strong>不成对的数据</strong>就能训练</p>
<p><strong>pix2pixHD：</strong>生成<strong>高分辨率、高质量</strong>的图片</p>
<p><img src="https://img-blog.csdn.net/20180914044518280?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dkeW1pbmQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="è¿éåå¾çæè¿°"></p>
<h3 id="pix2pix"><a href="#pix2pix" class="headerlink" title="pix2pix"></a>pix2pix</h3><p>对传统的GAN做了一个小改动，它不再输入随机噪声，而是输入用户给的图片：</p>
<p>然后建立输入和输出的对应关系：<strong>将G的输入和输出一起作为D的输入</strong></p>
<p><img src="https://img-blog.csdn.net/20180914044620941?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dkeW1pbmQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="è¿éåå¾çæè¿°"></p>
<h3 id="CycleGAN"><a href="#CycleGAN" class="headerlink" title="CycleGAN"></a>CycleGAN</h3><p>pix2pix必须使用成对的数据进行训练</p>
<p>而CycleGAN值需要输入数据的一个集合（比如一堆马的照片）和输出数据的一个集合（一如一堆斑马的照片）就可以了</p>
<p><img src="https://img-blog.csdn.net/20180914044822913?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dkeW1pbmQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="è¿éåå¾çæè¿°"></p>
<p>pix2pix</p>
<p><img src="https://img-blog.csdn.net/20180914044837669?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dkeW1pbmQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="è¿éåå¾çæè¿°"></p>
<p>CycleGAN</p>
<p><img src="https://img-blog.csdn.net/20180914044908950?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dkeW1pbmQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="è¿éåå¾çæè¿°"></p>
<p>但是，直接使用不成对的数据是不奏效的。网络会直接忽略输入，随机产生输出！所以需要对网络增加<strong>限制</strong></p>
<p>即我们如果将马变成斑马，然后再变成马，那么最后的马和开始输入的马应该是一样的</p>
<p>具体细节。除了之前提到的把马斑马的网络G，我们还需要一个把斑马变回马的网络F</p>
<p>那么，一匹马x用G变成斑马s = G(x)，然后再用F把它变回马F(s)，得到的马应该和一开始的马是一样的，即x = F(G(x))</p>
<p><img src="https://img-blog.csdn.net/20180914044947503?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dkeW1pbmQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="è¿éåå¾çæè¿°"></p>
<p>翻过来，斑马变成马再变回斑马也需要满足要求，注意这一步最好不要省略。</p>
<p>然后同时优化G和F，最后就能拿到一个想要的网络G</p>
<h4 id="CycleGAN为什么有效"><a href="#CycleGAN为什么有效" class="headerlink" title="CycleGAN为什么有效"></a>CycleGAN为什么有效</h4><p>CycleGAN成功的原因在于它分离了<strong>风格（Style）和内容（content）</strong>。人工设计这种分离的算法是很难的，但有了神经网络，我们很容易让它学习者去自动<strong>保持内容而改变风格</strong></p>
<p>存在的问题：CycleGAN只能输出256p/512p的低分辨率图片</p>
<h3 id="pix2pixHD"><a href="#pix2pixHD" class="headerlink" title="pix2pixHD"></a>pix2pixHD</h3><p>pix2pixHD采取了金字塔的方式</p>
<ul>
<li>先输出低分辨率的图片</li>
<li>将之前输出的低分辨率图片作为另一个网络的输入，然后生成分辨率更高的图片</li>
</ul>
<p><img src="https://img-blog.csdn.net/20180914045410513?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dkeW1pbmQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="è¿éåå¾çæè¿°"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woojoo520.github.io/2019/08/23/GAN-pix2pix-CycleGAN-pix3pixHD/" data-id="cjztit1mb00019guj8zvuwhkc" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/08/25/LeetCode-Day11/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          LeetCode-Day11
        
      </div>
    </a>
  
  
    <a href="/2019/08/22/GCN/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">GCN</div>
    </a>
  
</nav>

  
</article>

</section>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Mariana<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<script src="/js/script.js"></script>

  </div>
</body>
</html>