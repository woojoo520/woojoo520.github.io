<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>ZSL | Celery Fairy</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="ZSL的相关论文 基于attribute description构建语义空间A  $Learning To Detect Unseen Object Classes by Between-Class Attribute Transfer$ http://pub.ist.ac.at/~chl/papers/lampert-cvpr2009.pdf 基于attribute description的方法">
<meta property="og:type" content="article">
<meta property="og:title" content="ZSL">
<meta property="og:url" content="https://woojoo520.github.io/2019/08/21/ZSL/index.html">
<meta property="og:site_name" content="Celery Fairy">
<meta property="og:description" content="ZSL的相关论文 基于attribute description构建语义空间A  $Learning To Detect Unseen Object Classes by Between-Class Attribute Transfer$ http://pub.ist.ac.at/~chl/papers/lampert-cvpr2009.pdf 基于attribute description的方法">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://blog.openkg.cn/wp-content/uploads/2018/11/word-image-3.jpeg">
<meta property="og:image" content="http://blog.openkg.cn/wp-content/uploads/2018/11/word-image-4.jpeg">
<meta property="og:image" content="http://blog.openkg.cn/wp-content/uploads/2018/11/word-image-6.jpeg">
<meta property="og:image" content="http://blog.openkg.cn/wp-content/uploads/2018/11/word-image-10.jpeg">
<meta property="og:image" content="http://blog.openkg.cn/wp-content/uploads/2018/11/word-image-13.jpeg">
<meta property="og:image" content="http://blog.openkg.cn/wp-content/uploads/2018/11/word-image-15.jpeg">
<meta property="og:updated_time" content="2019-08-21T13:27:53.162Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ZSL">
<meta name="twitter:description" content="ZSL的相关论文 基于attribute description构建语义空间A  $Learning To Detect Unseen Object Classes by Between-Class Attribute Transfer$ http://pub.ist.ac.at/~chl/papers/lampert-cvpr2009.pdf 基于attribute description的方法">
<meta name="twitter:image" content="http://blog.openkg.cn/wp-content/uploads/2018/11/word-image-3.jpeg">
  
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Celery Fairy</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
      </nav>
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://woojoo520.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-ZSL" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/08/21/ZSL/" class="article-date">
  <time datetime="2019-08-21T08:42:41.000Z" itemprop="datePublished">2019-08-21</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      ZSL
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="ZSL的相关论文"><a href="#ZSL的相关论文" class="headerlink" title="ZSL的相关论文"></a>ZSL的相关论文</h2><ol>
<li>基于attribute description构建语义空间A</li>
</ol>
<p>$Learning To Detect Unseen Object Classes by Between-Class Attribute Transfer$</p>
<p><a href="http://pub.ist.ac.at/~chl/papers/lampert-cvpr2009.pdf" target="_blank" rel="noopener">http://pub.ist.ac.at/~chl/papers/lampert-cvpr2009.pdf</a></p>
<p>基于attribute description的方法，其数据集中的每张图片都标注了若干attribute用以描述图片信息。一些标注了attribute的示例图片如下图所示</p>
<p><img src="http://blog.openkg.cn/wp-content/uploads/2018/11/word-image-3.jpeg" alt="img"></p>
<p>这篇论文通过上述每张图片预定义的特征，构建了样本数据的特征表示空间X；同时，通过若干classes集合或图片集合学习可用于表示数据集中所有class的attribute description，完成语义空间A的构建；最后，论文提出了使用两种方式建立X和A之间的映射。两种方式为：Direct Attribute Prediction（DAP）和 Indirect Attribute Prediction（IAP），如下图所示：</p>
<p><img src="http://blog.openkg.cn/wp-content/uploads/2018/11/word-image-4.jpeg" alt="img"></p>
<p><strong>DAP：</strong></p>
<p>训练时，由一直标签的训练集，学习有关attribute的参数β；预测时，为每一个测试样本预测其attribute参数，进而根据attribute建立的seen class(y) 和 unseen class(z)之间的关系，推导得出测试样本的label</p>
<p><strong>IAP：</strong></p>
<p>训练时，按多分类的方式学习参数α；预测时，根据attribute建立的seen class(y) 和 unseen class(z)之间的关系，推到得到unseen class 的分布。</p>
<p>DAP在训练是仅依据属性层，而IAP将训练样本的类标也作为一个中间层，一定程度上能限定测试样本生成新类标的范围，使得学习到的链接控制在对于Y来说，有意义的范围之内，因此可以增强系统的鲁棒性。但实际上，在作者后面的实验中，DAP的效果要比IAP好很多</p>
<p>效果虽然不是很好，但确实在一定程度上表达了“知识迁移”的思想，不仅利用图片训练相应的特征，更是加入了属性这类的高位特征描述，实现了“从低维图片特征分类器”到“高位语义特征（属性）分类器”的转变</p>
<p><strong>Attribute description相关论文列表：</strong></p>
<ul>
<li><cvpr-2009>Describing Objects by their Attributes</cvpr-2009></li>
<li><tpami-2014>Attribute-based Classification for Zero-Shot Visual Object Categorization</tpami-2014></li>
<li><tpami-2017>Zero-Shot Learning-A Comprehensive Evaluation of the Good, the Bad and the Ugly</tpami-2017></li>
<li><cvpr-2017>Semantic Autoencoder for Zero-Shot Learning</cvpr-2017></li>
<li><cvpr-2016>Recovering the Missing Link: Predicting Class-Attribute Associations for Unsupervised Zero-Shot Learning</cvpr-2016></li>
</ul>
<h3 id="2-基于embedding表示构建语义空间A"><a href="#2-基于embedding表示构建语义空间A" class="headerlink" title="2. 基于embedding表示构建语义空间A"></a>2. 基于embedding表示构建语义空间A</h3><p>$DeViSE: A Deep Visual-Semantic Embedding Model$</p>
<p><a href="http://papers.nips.cc/paper/5204-devise-a-deep-visual-semantic-embedding-model.pdf" target="_blank" rel="noopener">http://papers.nips.cc/paper/5204-devise-a-deep-visual-semantic-embedding-model.pdf</a></p>
<p>本文提出的DeViSE模型，数据集每个class/label可作为一个词在语义空间进行embedding表示，如使用与训练skip-gram模型得到有关class的language feature vector，同时利用与训练的CNN-based模型提取图片的visual feature vector，将两个向量映射到同一纬度的空间，进行相似度的计算。测试时，即可根据语义之间的相似性进行图片的分类。模型结构如下图：</p>
<p><img src="http://blog.openkg.cn/wp-content/uploads/2018/11/word-image-6.jpeg" alt="img"></p>
<p>考虑到训练时负样本发挥的通，模型的损失函数选择hinge loss。其中，通过dot-product 计算相似度。</p>
<p>$\text {loss(image,label)}=\sum_{j \neq l a b e l} \max \left[0, \text {margin }-\overrightarrow{t_{l a b e l}} M \vec{v}(\text {image})+\vec{t}_{j} M \vec{v}(\text {image})\right]$</p>
<p><strong>Embedding表示相关论文列表：</strong></p>
<ul>
<li><iccv-2015>Predicting Deep Zero-Shot Convolutional Neural Networks using TextualDescriptions</iccv-2015></li>
<li><cvpr-2016>Learning Deep Representations of Fine-grained Visual Descriptions</cvpr-2016></li>
<li><cvpr-2015>Evaluation of Output Embeddings for Fine-grained Image Classification</cvpr-2015></li>
<li><cvpr-2016>Latent Embeddings for Zero-shot Classification</cvpr-2016></li>
</ul>
<h3 id="3-基于KG-KB构建语义空间A"><a href="#3-基于KG-KB构建语义空间A" class="headerlink" title="3. 基于KG/KB构建语义空间A"></a>3. 基于KG/KB构建语义空间A</h3><h4 id="3-1-Zero-shot-Recognition-via-Semantic-Embeddings-and-Knowledge-Graphs"><a href="#3-1-Zero-shot-Recognition-via-Semantic-Embeddings-and-Knowledge-Graphs" class="headerlink" title="3.1 $Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs$"></a>3.1 $Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs$</h4><p>本文基于Graph COnvolution Network(GCN，一种处理Graph-structured数据的神经网络)引入Knowledge Graph的hierarchy结构进行计算。模型分为两个独立的部分，首先使用CNN-based方法（如resnet， Inception等）为输入的图片抽取特征向量，即CNN部分（图所示上方的CNN网络）；其次，GCN部分（图所示下方的GCN网络）将数据集中的每个class作为Graph中的一个节点，并对其做embedding表示输入GCN网络（即输入为有N个k为节点组成的N * k特征矩阵），通过神经网络每一层之间信息的传递和计算，为每个节点（class）输出一组权重向量（D维），即输出是一个N * D的特征矩阵。</p>
<p><img src="http://blog.openkg.cn/wp-content/uploads/2018/11/word-image-10.jpeg" alt="img"></p>
<p>模型训练时，Graph中seen class节点有来自CNN部分的图片特征向量作为监督信号（图所示绿色节点）训练GCN模型的参数；而测试时，Graph中的unseen class节点输出对应的权重向量，同时，与CNN部分对应图片输出的特征向量，最终得到分类的结果。</p>
<p>这里提及的Graph为克表示ImageNet class之间结构的WorldNet知识库，实验选取了其中一部分与ImageNet相关的子集</p>
<h4 id="3-2-Rethinking-Knowledge-Graph-Propagation-for-Zero-Shot-Learning"><a href="#3-2-Rethinking-Knowledge-Graph-Propagation-for-Zero-Shot-Learning" class="headerlink" title="3.2 $Rethinking Knowledge Graph Propagation for Zero-Shot Learning$"></a>3.2 $Rethinking Knowledge Graph Propagation for Zero-Shot Learning$</h4><p><a href="https://arxiv.org/pdf/1805.11724v1.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1805.11724v1.pdf</a></p>
<p>在1的基础上进行了改进，包括以下几个方面：</p>
<ul>
<li><p>更少的GCN层数，论文1中使用了6层神经网络进行训练，考虑到模型参数的优化问题，本文只使用了2层神经网络进行计算，即GPM</p>
</li>
<li><p>减少层数的同时，一些较远节点不被考虑在内，为了解决这个问题，作者将一些节点的祖先/子孙节点直接与该节点相连，生成了更密集的图，即DGPM；同时，这些直接相连的边按照距离的远近，加入attention机制进行了加权计算，即ADGPM</p>
</li>
<li><p>作者还提出了在CNN部分根据Graph信息进行fine tune的计算方式，使得提取图片特征的卷积网络可根据一些新出现的class进行更新</p>
</li>
</ul>
<p><strong>KG/KB相关论文列表：</strong></p>
<ul>
<li><ijcai-2018>Fine-grained Image Classification by Visual-Semantic Embedding</ijcai-2018></li>
<li><cvpr-2018>Multi-Label Zero-Shot Learning with Structured Knowledge Graphs</cvpr-2018></li>
<li><nips-2009>Zero-Shot Learning with Semantic Output Codes</nips-2009></li>
<li>少样本学习（Few-Shot Learning, FSL）</li>
</ul>
<p>前面 2.2 部分提到的论文，其迁移知识的方式主要是通过在语义空间构建 seen class 与 unseen class 之间的关系（下图左），而 Transductive Setting 则提出可通过 seen class 和 unseen class 的少量样本训练得到class之间的关联（下图右），即少样本学习（Few-ShotLearning, FSL）。</p>
<p><img src="http://blog.openkg.cn/wp-content/uploads/2018/11/word-image-13.jpeg" alt="img"></p>
<h3 id="FSL–Few-ShotLearning-少样本学习"><a href="#FSL–Few-ShotLearning-少样本学习" class="headerlink" title="FSL–Few-ShotLearning(少样本学习)"></a>FSL–Few-ShotLearning(少样本学习)</h3><h4 id="Learning-to-Compare-RelationNetwork-for-Few-Shot-Learning"><a href="#Learning-to-Compare-RelationNetwork-for-Few-Shot-Learning" class="headerlink" title="$Learning to Compare: RelationNetwork for Few-Shot Learning$"></a>$Learning to Compare: RelationNetwork for Few-Shot Learning$</h4><p><a href="https://arxiv.org/pdf/1711.06025.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1711.06025.pdf</a></p>
<p>本文从每个 class 中采样少量样本，作为参考样本（如下图左侧 5 张图片，分别代表 5 个 classes），以建立 class 之间的关系。本文所构建的 class relation 主要为相似关系，模型通过 embedding module 提取图片的特征向量，再分别将测试图片（下图所示袋鼠图片）的特征向量与参考样本的特征向量进行拼接输入 relation module，通过神经网络计算测试图片和参考样本图片之间的相似性，最终判断测试图片属于参考图片代表 class 的哪一类。</p>
<p><img src="http://blog.openkg.cn/wp-content/uploads/2018/11/word-image-15.jpeg" alt="img"></p>
<p><strong>FSL相关论文列表：</strong></p>
<ul>
<li><iclr-2018>Few-Shot Learning with Graph Neural Networks</iclr-2018></li>
<li><bigdata-2017>One-shot Learning for Fine-grained Relation Extraction via ConvolutionalSiamese Neural Network</bigdata-2017></li>
<li><nips-2016>Matching Networks for One Shot Learning</nips-2016></li>
<li><nips-2017>Prototypical Networks for Few-hot Learning</nips-2017></li>
<li><iclr-2017>Optimization as a model for few-shot learning</iclr-2017></li>
<li><icml-2016>Meta-learningwith Memory-augmented Neural Networks</icml-2016></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woojoo520.github.io/2019/08/21/ZSL/" data-id="cjztit1nd000t9gujo1mcjeq9" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/08/21/LeetCode-Day7/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          LeetCode-Day7
        
      </div>
    </a>
  
  
    <a href="/2019/08/20/LeetCode-Day6/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">LeetCode-Day6</div>
    </a>
  
</nav>

  
</article>

</section>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Mariana<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<script src="/js/script.js"></script>

  </div>
</body>
</html>