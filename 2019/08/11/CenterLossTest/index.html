<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>CenterLossTest | Celery Fairy</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="CenterLossTest class torch.nn.PReLU(num_paramenter=1, init=0.25) 对输入的每一个元素运用函数 $PReLU(x) = max(0,x) + a*min(0, x)$，a是一个可学习参数。当没有声明时，nn.PReLU()在所有的输入中只有一个参数a；如果是nn.PReLU(nChannels)，a将应用到每个输入。 注意：当为了表现更">
<meta property="og:type" content="article">
<meta property="og:title" content="CenterLossTest">
<meta property="og:url" content="https://woojoo520.github.io/2019/08/11/CenterLossTest/index.html">
<meta property="og:site_name" content="Celery Fairy">
<meta property="og:description" content="CenterLossTest class torch.nn.PReLU(num_paramenter=1, init=0.25) 对输入的每一个元素运用函数 $PReLU(x) = max(0,x) + a*min(0, x)$，a是一个可学习参数。当没有声明时，nn.PReLU()在所有的输入中只有一个参数a；如果是nn.PReLU(nChannels)，a将应用到每个输入。 注意：当为了表现更">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2019-08-11T13:47:00.935Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CenterLossTest">
<meta name="twitter:description" content="CenterLossTest class torch.nn.PReLU(num_paramenter=1, init=0.25) 对输入的每一个元素运用函数 $PReLU(x) = max(0,x) + a*min(0, x)$，a是一个可学习参数。当没有声明时，nn.PReLU()在所有的输入中只有一个参数a；如果是nn.PReLU(nChannels)，a将应用到每个输入。 注意：当为了表现更">
  
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Celery Fairy</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
      </nav>
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://woojoo520.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-CenterLossTest" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/08/11/CenterLossTest/" class="article-date">
  <time datetime="2019-08-11T07:26:38.000Z" itemprop="datePublished">2019-08-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      CenterLossTest
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="CenterLossTest"><a href="#CenterLossTest" class="headerlink" title="CenterLossTest"></a>CenterLossTest</h2><ul>
<li><p><code>class torch.nn.PReLU(num_paramenter=1, init=0.25)</code></p>
<p>对输入的每一个元素运用函数 $PReLU(x) = max(0,x) + a*min(0, x)$，<code>a</code>是一个可学习参数。当没有声明时，<code>nn.PReLU()</code>在所有的输入中只有一个参数a；如果是<code>nn.PReLU(nChannels)</code>，a将应用到每个输入。</p>
<p><strong>注意：</strong>当为了表现更加的模型而学习参数a时不要使用权重衰减</p>
<p>参数：</p>
<ul>
<li>num_parameters：需要学习的a的个数，默认等于1</li>
<li>init：a的初始值，默认等于0.25</li>
</ul>
<p>shape：</p>
<ul>
<li>输入：$(N, )$，代表任意数目附加维度</li>
<li>输出：$(N,*)$，与输入拥有同样的shape属性</li>
</ul>
</li>
<li><p><code>nn.Linear(in_features, out_features, bias=True)</code></p>
<p>具体形式为：<code>y = wx + b</code></p>
<p><code>weight = Parameter(torch.Tensor(out_features, in_features))</code></p>
<p><code>bias = Parameter(torch.Tensor(out_features))</code></p>
<p><code>bias</code>如果设置为False，则图层不会学习附加偏差。默认值：True</p>
</li>
<li><p><code>self.v = torch.nn.Parameters()</code></p>
<p>可以把这个函数理解为类型转换函数，讲一个不可训练的类型<code>Tensor</code>转换成可以训练的类型<code>parameter</code>，并将这个<code>parameter</code>绑定到这个<code>module</code>里面(<code>net.parameter()</code>中就有这个绑定的<code>parameter</code>，所以在参数优化的时候可以进行优化的)，所以经过类型转换这个<code>self.v</code>变成了模型的一部分，成为了模型中根据训练可以改动的参数了。使用这个函数的目的也是想让某些变量在学习的过程中不断的修改其值以达到最优化</p>
</li>
<li><p><code>torch.pow()</code></p>
<p>这里对应的矩阵乘法只是每一位上的乘法</p>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line">a = torch.rand(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">print(a)</span><br><span class="line">b = torch.pow(a)</span><br><span class="line">print(b)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">output：</span></span><br><span class="line"><span class="string">tensor([[-0.6702,  0.1811],</span></span><br><span class="line"><span class="string">        [-0.7064, -0.3418]])</span></span><br><span class="line"><span class="string">tensor([[0.4491, 0.0328],</span></span><br><span class="line"><span class="string">        [0.4990, 0.1168]])</span></span><br><span class="line"><span class="string">0.4491 = (-0.6702)*(-0.6702)        </span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>torch.sum(input, dim, out=None)</code>  <code>----&gt;Tensor</code></p>
<p>返回输入张量给定维度上每行的和。输出形状与输入相同，除了给定维度上为1.</p>
<p>参数：</p>
<ul>
<li>input(Tensor)——输入张量</li>
<li>dim(int)——缩减的维度</li>
<li>out(Tensor, optional)——结果张量</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line">a = torch.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">print(a)</span><br><span class="line">print(torch.sum(a, <span class="number">1</span>))</span><br><span class="line">print(torch.sum(a))</span><br><span class="line">print(torch.sum(a, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>))</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">output:</span></span><br><span class="line"><span class="string">tensor([[-0.9850, -0.6207, -0.6559, -0.1220],</span></span><br><span class="line"><span class="string">        [-1.0619,  0.0158, -1.0086,  0.3370],</span></span><br><span class="line"><span class="string">        [ 0.5729, -1.7753,  1.2464, -1.6284],</span></span><br><span class="line"><span class="string">        [-0.3275, -0.5711, -0.6691,  1.2357]])</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">tensor([-2.3836, -1.7177, -1.5843, -0.3320])	# 变成了行向量</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">tensor(-6.0177)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">tensor([[-2.3836],</span></span><br><span class="line"><span class="string">        [-1.7177],</span></span><br><span class="line"><span class="string">        [-1.5843],</span></span><br><span class="line"><span class="string">        [-0.3320]])	# 仍然保持了列向量</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>expand</code></p>
<p>扩展某个size为1的维度。如(2, 2, 1)扩展为(2, 2, 3)</p>
<p>举例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">print(x)</span><br><span class="line">y = x.expand(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">print(y)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">output:</span></span><br><span class="line"><span class="string">tensor([[[ 0.3814],</span></span><br><span class="line"><span class="string">         [ 1.4493]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[-0.0204],</span></span><br><span class="line"><span class="string">         [-0.9141]]])</span></span><br><span class="line"><span class="string">     </span></span><br><span class="line"><span class="string">tensor([[[ 0.3814,  0.3814,  0.3814],</span></span><br><span class="line"><span class="string">         [ 1.4493,  1.4493,  1.4493]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[-0.0204, -0.0204, -0.0204],</span></span><br><span class="line"><span class="string">         [-0.9141, -0.9141, -0.9141]]])     </span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>torch.squeeze()</code></p>
<p>将维度为1的压缩掉。如size为(3, 1, 1, 2)，压缩之后为(3, 2)</p>
<p>举例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line">a = torch.randn(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">print(a)</span><br><span class="line">print(a.squeeze())</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">output:</span></span><br><span class="line"><span class="string">tensor([[[[ 2.2045,  0.2968,  0.2945]]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[[ 0.2579,  0.9719, -0.8220]]]])</span></span><br><span class="line"><span class="string">tensor([[ 2.2045,  0.2968,  0.2945],</span></span><br><span class="line"><span class="string">        [ 0.2579,  0.9719, -0.8220]])        </span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>torch.unsqueeze(input, dim, out=None)</code></p>
<p>返回一个新的张量，对输入的指定位置插入维度1</p>
<p><strong>注意：</strong>返回张量与输入张量共享内存，所以改变其中一个的内容会改变另一个</p>
<p>如果dim为负，则会被转换为<code>dim + input.dim() + 1</code></p>
<p>参数：</p>
<ul>
<li>tensor(Tensor)——输入张量</li>
<li>dim(int)——插入维度的索引</li>
<li>out(Tensor, optional)——结果张量</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line">a = torch.randn(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">print(a)</span><br><span class="line">b = a.unsqueeze(<span class="number">1</span>)</span><br><span class="line">print(b)</span><br><span class="line">print(b.size())</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">output:</span></span><br><span class="line"><span class="string">tensor([[-0.2329,  0.0805]])</span></span><br><span class="line"><span class="string">tensor([[[-0.2329,  0.0805]]])</span></span><br><span class="line"><span class="string">torch.Size([1, 1, 2])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p><code>t()</code>     转置</p>
</li>
<li><p><code>torch.addmm(beta-1, mat, alpha=1, mat1, mat2, out=None)    ----&gt;Tensor</code></p>
<p>对矩阵mat1和mat2进行矩阵乘操作，矩阵mat加到最终结果。alpha和beta分别是两个矩阵mat1×mat2和mat的比例因子，即$out=(beta * M) + (alpha * mat1 × mat2)$</p>
<p>对类型为FloatTensor或DoubleTensor的输入，beta和alpha必须为实数，否则两个参数必须为整数</p>
<p>举例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line">a = torch.randn(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">b = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">c = torch.randn(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br><span class="line">print(c)</span><br><span class="line">print(a.addmm(<span class="number">1</span>, <span class="number">2</span>, b, c))</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">output:</span></span><br><span class="line"><span class="string">tensor([[ 1.2774,  0.2344],</span></span><br><span class="line"><span class="string">        [-0.2572,  0.0019]])</span></span><br><span class="line"><span class="string">tensor([[0.4277, 0.8812, 0.7919],</span></span><br><span class="line"><span class="string">        [0.5476, 0.2299, 0.9781]])</span></span><br><span class="line"><span class="string">tensor([[-1.2772, -0.9458],</span></span><br><span class="line"><span class="string">        [ 1.6094,  0.7200],</span></span><br><span class="line"><span class="string">        [ 0.0633,  0.0571]])</span></span><br><span class="line"><span class="string">tensor([[ 3.1216,  0.7847],</span></span><br><span class="line"><span class="string">        [-0.7920, -0.5911]])</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>torch.clamp(input, min, max, out=None)   ---&gt;Tensor</code></p>
<p>将输入input张量每个元素都夹紧到区间[min, max]，并返回结果到一个新张量。</p>
<p>举例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line">a = torch.randint(low=<span class="number">0</span>, high=<span class="number">10</span>, size=(<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">print(a)</span><br><span class="line">a = torch.clamp(a, <span class="number">3</span>, <span class="number">7</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">output:</span></span><br><span class="line"><span class="string">tensor([[1, 1, 4],</span></span><br><span class="line"><span class="string">        [8, 9, 2]])</span></span><br><span class="line"><span class="string">tensor([[3, 3, 4],</span></span><br><span class="line"><span class="string">        [7, 7, 3]])        </span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>

<p>$y_{i}=\left{\begin{array}{l}{ min, x_{i} &lt; min} \ {x_{i}, min \leq x_{i} \leq max} \ {max, x_{i} &gt; max}\end{array}\right.$</p>
</li>
<li><p><code>torch.eq()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line">outputs = torch.FloatTensor([[<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>]])</span><br><span class="line">targets = torch.FloatTensor([[<span class="number">0</span>], [<span class="number">2</span>], [<span class="number">3</span>]])</span><br><span class="line">print(targets.eq(outputs.data))	<span class="comment"># 比较相等</span></span><br><span class="line">print(targets.eq(outputs.data).cpu().sum())	<span class="comment"># 统计相等的个数</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">output:</span></span><br><span class="line"><span class="string">tensor([[False],</span></span><br><span class="line"><span class="string">        [ True],</span></span><br><span class="line"><span class="string">        [ True]])</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">tensor(2)</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>

</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woojoo520.github.io/2019/08/11/CenterLossTest/" data-id="cjzyylppc0000qsujjrlxnwuo" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/08/14/parser-action/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          parser-action
        
      </div>
    </a>
  
  
    <a href="/2019/08/09/NormFace/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">NormFace</div>
    </a>
  
</nav>

  
</article>

</section>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Mariana<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<script src="/js/script.js"></script>

  </div>
</body>
</html>